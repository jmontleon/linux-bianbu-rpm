From c096c9c82b83f982432b307f9c5a8f70604ceda2 Mon Sep 17 00:00:00 2001
From: lizhirong <zhirong.li@spacemit.com>
Date: Wed, 13 Dec 2023 10:10:07 +0800
Subject: [PATCH 0198/1204] support jpu driver for k1x

Change-Id: I2091ead52ae80d5c9b663263ee9c52568d460577
---
 arch/riscv/boot/dts/spacemit/k1-x.dtsi |   21 +-
 drivers/soc/spacemit/Kconfig           |    2 +
 drivers/soc/spacemit/Makefile          |    1 +
 drivers/soc/spacemit/jpu/Kconfig       |   11 +
 drivers/soc/spacemit/jpu/Makefile      |    4 +
 drivers/soc/spacemit/jpu/config.h      |   21 +
 drivers/soc/spacemit/jpu/jmm.h         |  570 ++++++++
 drivers/soc/spacemit/jpu/jpu.c         | 1803 ++++++++++++++++++++++++
 drivers/soc/spacemit/jpu/jpu.h         |   91 ++
 drivers/soc/spacemit/jpu/jpu_export.c  |  302 ++++
 drivers/soc/spacemit/jpu/jpu_export.h  |    7 +
 drivers/soc/spacemit/jpu/jpuconfig.h   |   43 +
 drivers/soc/spacemit/jpu/regdefine.h   |  141 ++
 13 files changed, 3016 insertions(+), 1 deletion(-)
 create mode 100644 drivers/soc/spacemit/jpu/Kconfig
 create mode 100644 drivers/soc/spacemit/jpu/Makefile
 create mode 100644 drivers/soc/spacemit/jpu/config.h
 create mode 100644 drivers/soc/spacemit/jpu/jmm.h
 create mode 100644 drivers/soc/spacemit/jpu/jpu.c
 create mode 100644 drivers/soc/spacemit/jpu/jpu.h
 create mode 100644 drivers/soc/spacemit/jpu/jpu_export.c
 create mode 100644 drivers/soc/spacemit/jpu/jpu_export.h
 create mode 100644 drivers/soc/spacemit/jpu/jpuconfig.h
 create mode 100644 drivers/soc/spacemit/jpu/regdefine.h

diff --git a/arch/riscv/boot/dts/spacemit/k1-x.dtsi b/arch/riscv/boot/dts/spacemit/k1-x.dtsi
index dbb94923050b..af80d7f78630 100644
--- a/arch/riscv/boot/dts/spacemit/k1-x.dtsi
+++ b/arch/riscv/boot/dts/spacemit/k1-x.dtsi
@@ -1634,7 +1634,26 @@ v2d@c0100000 {
 			interrupts = <86>;
 			status = "ok";
 		};
-
+		jpu@c02f8000 {
+			compatible = "chip-media, jpu";
+			reg = <0 0xc02f8000 0 0x700>;
+			interrupt-parent = <&intc>;
+			interrupts = <87>;
+			jpu,chip-id = <0>;
+			clocks = <&ccu CLK_JPG>,
+				<&ccu CLK_DPU_MCLK>,
+				<&ccu CLK_ISP_BUS>;
+			clock-names ="cclk", "aclk", "iclk";
+			resets = <&reset RESET_ISP>,
+					<&reset RESET_ISP_AHB>;
+			reset-names = "freset", "sreset";
+			jpu,cclk-max-frequency = /bits/ 64 <1000000000>;
+			jpu,cclk-min-frequency = <409000000>;
+			jpu,cclk-default-frequency = <614000000>;
+			//power-domains = <&spacemit_pds PD_COMMON_ISP>;
+			status = "okay";
+			page-size = <4>;
+		};
 		display-subsystem {
 			compatible = "spacemit,saturn-le";
 			reg = <0 0xC0340000 0 0x2A000>;
diff --git a/drivers/soc/spacemit/Kconfig b/drivers/soc/spacemit/Kconfig
index 65c1e723f48b..6ef88f2bbbdd 100644
--- a/drivers/soc/spacemit/Kconfig
+++ b/drivers/soc/spacemit/Kconfig
@@ -14,3 +14,5 @@ config SPACEMIT_PM_DOMAINS
 	  management unit is designed or saving power.
 
 endif
+
+source "drivers/soc/spacemit/jpu/Kconfig"
diff --git a/drivers/soc/spacemit/Makefile b/drivers/soc/spacemit/Makefile
index f6fba0ac9094..d29e71be0e0d 100644
--- a/drivers/soc/spacemit/Makefile
+++ b/drivers/soc/spacemit/Makefile
@@ -1 +1,2 @@
 obj-$(CONFIG_SPACEMIT_PM_DOMAINS) += pm_domain/
+obj-$(CONFIG_CHIP_MEDIA_JPU)    += jpu/
diff --git a/drivers/soc/spacemit/jpu/Kconfig b/drivers/soc/spacemit/jpu/Kconfig
new file mode 100644
index 000000000000..c31eb5090e21
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/Kconfig
@@ -0,0 +1,11 @@
+config CHIP_MEDIA_JPU
+	tristate "chip media jpu driver"
+	help
+		This enables the chip media jpu driver
+
+config JPU_ENABLE_DEBUG_MSG
+	depends on CHIP_MEDIA_JPU
+	bool "chip media jpu driver debug"
+	default n
+	help
+		This enabled debug message output
diff --git a/drivers/soc/spacemit/jpu/Makefile b/drivers/soc/spacemit/jpu/Makefile
new file mode 100644
index 000000000000..afdfed75d38d
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/Makefile
@@ -0,0 +1,4 @@
+# SPDX-License-Identifier: GPL-2.0
+
+obj-$(CONFIG_CHIP_MEDIA_JPU) += jpu.o jpu_export.o
+ccflags-${CONFIG_JPU_ENABLE_DEBUG_MSG} += -DENABLE_DEBUG_MSG
diff --git a/drivers/soc/spacemit/jpu/config.h b/drivers/soc/spacemit/jpu/config.h
new file mode 100644
index 000000000000..5522f5ca2285
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/config.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef __CONFIG_H__
+#define __CONFIG_H__
+
+#if defined(_WIN32) || defined(__WIN32__) || defined(_WIN64) || defined(WIN32) || defined(__MINGW32__)
+#	define PLATFORM_WIN32
+#elif defined(linux) || defined(__linux) || defined(ANDROID)
+#	define PLATFORM_LINUX
+#else
+#	define PLATFORM_NON_OS
+#endif
+
+#if defined(CNM_FPGA_PLATFORM) || defined(CNM_SIM_PLATFORM)
+#ifdef ANDROID
+#else
+#endif
+#endif
+
+#define API_VERSION 0x124
+
+#endif /* __CONFIG_H__ */
diff --git a/drivers/soc/spacemit/jpu/jmm.h b/drivers/soc/spacemit/jpu/jmm.h
new file mode 100644
index 000000000000..2b0717390907
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jmm.h
@@ -0,0 +1,570 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef __CNM_JPU_MM_H__
+#define __CNM_JPU_MM_H__
+
+typedef unsigned long long jmem_key_t;
+
+#define JMEM_PAGE_SIZE           (16*1024)
+#define MAKE_KEY(_a, _b)        (((jmem_key_t)_a)<<32 | _b)
+#define KEY_TO_VALUE(_key)      (_key>>32)
+
+typedef struct page_struct {
+	int pageno;
+	unsigned long addr;
+	int used;
+	int alloc_pages;
+	int first_pageno;
+} page_t;
+
+typedef struct avl_node_struct {
+	jmem_key_t key;
+	int height;
+	page_t *page;
+	struct avl_node_struct *left;
+	struct avl_node_struct *right;
+} avl_node_t;
+
+typedef struct _jpu_mm_struct {
+	avl_node_t *free_tree;
+	avl_node_t *alloc_tree;
+	page_t *page_list;
+	int num_pages;
+	unsigned long base_addr;
+	unsigned long mem_size;
+	int free_page_count;
+	int alloc_page_count;
+} jpu_mm_t;
+
+#define VMEM_P_ALLOC(_x)         kmalloc(_x, GFP_KERNEL)
+#define VMEM_P_FREE(_x)          kfree(_x)
+
+#define VMEM_ASSERT(_exp)        if (!(_exp)) { printk(KERN_INFO "VMEM_ASSERT at %s:%d\n", __FILE__, __LINE__); /*while(1);*/ }
+#define VMEM_HEIGHT(_tree)       (_tree==NULL ? -1 : _tree->height)
+
+#define MAX(_a, _b)         (_a >= _b ? _a : _b)
+
+typedef enum {
+	LEFT,
+	RIGHT
+} rotation_dir_t;
+
+typedef struct avl_node_data_struct {
+	int key;
+	page_t *page;
+} avl_node_data_t;
+
+static avl_node_t *make_avl_node(jmem_key_t key, page_t *page)
+{
+	avl_node_t *node = (avl_node_t *) VMEM_P_ALLOC(sizeof(avl_node_t));
+	node->key = key;
+	node->page = page;
+	node->height = 0;
+	node->left = NULL;
+	node->right = NULL;
+
+	return node;
+}
+
+static int get_balance_factor(avl_node_t *tree)
+{
+	int factor = 0;
+	if (tree)
+		factor = VMEM_HEIGHT(tree->right) - VMEM_HEIGHT(tree->left);
+
+	return factor;
+}
+
+/*
+ * Left Rotation
+ *
+ *      A                      B
+ *       \                    / \
+ *        B         =>       A   C
+ *       /  \                 \
+ *      D    C                 D
+ *
+ */
+static avl_node_t *rotation_left(avl_node_t *tree)
+{
+	avl_node_t *rchild;
+	avl_node_t *lchild;
+
+	if (tree == NULL)
+		return NULL;
+
+	rchild = tree->right;
+	if (rchild == NULL) {
+		return tree;
+	}
+
+	lchild = rchild->left;
+	rchild->left = tree;
+	tree->right = lchild;
+
+	tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+	rchild->height = MAX(VMEM_HEIGHT(rchild->left), VMEM_HEIGHT(rchild->right)) + 1;
+
+	return rchild;
+}
+
+/*
+ * Reft Rotation
+ *
+ *         A                  B
+ *       \                  /  \
+ *      B         =>       D    A
+ *    /  \                     /
+ *   D    C                   C
+ *
+ */
+static avl_node_t *rotation_right(avl_node_t *tree)
+{
+	avl_node_t *rchild;
+	avl_node_t *lchild;
+
+	if (tree == NULL)
+		return NULL;
+
+	lchild = tree->left;
+	if (lchild == NULL)
+		return NULL;
+
+	rchild = lchild->right;
+	lchild->right = tree;
+	tree->left = rchild;
+
+	tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+	lchild->height = MAX(VMEM_HEIGHT(lchild->left), VMEM_HEIGHT(lchild->right)) + 1;
+
+	return lchild;
+}
+
+static avl_node_t *do_balance(avl_node_t *tree)
+{
+	int bfactor = 0, child_bfactor;	/* balancing factor */
+
+	bfactor = get_balance_factor(tree);
+
+	if (bfactor >= 2) {
+		child_bfactor = get_balance_factor(tree->right);
+		if (child_bfactor == 1 || child_bfactor == 0) {
+			tree = rotation_left(tree);
+		} else if (child_bfactor == -1) {
+			tree->right = rotation_right(tree->right);
+			tree = rotation_left(tree);
+		} else {
+			printk(KERN_INFO "invalid balancing factor: %d\n", child_bfactor);
+			VMEM_ASSERT(0);
+			return NULL;
+		}
+	} else if (bfactor <= -2) {
+		child_bfactor = get_balance_factor(tree->left);
+		if (child_bfactor == -1 || child_bfactor == 0) {
+			tree = rotation_right(tree);
+		} else if (child_bfactor == 1) {
+			tree->left = rotation_left(tree->left);
+			tree = rotation_right(tree);
+		} else {
+			printk(KERN_INFO "invalid balancing factor: %d\n", child_bfactor);
+			VMEM_ASSERT(0);
+			return NULL;
+		}
+	}
+
+	return tree;
+}
+
+static avl_node_t *unlink_end_node(avl_node_t *tree, int dir, avl_node_t **found_node)
+{
+	avl_node_t *node;
+	*found_node = NULL;
+
+	if (tree == NULL)
+		return NULL;
+
+	if (dir == LEFT) {
+		if (tree->left == NULL) {
+			*found_node = tree;
+			return NULL;
+		}
+	} else {
+		if (tree->right == NULL) {
+			*found_node = tree;
+			return NULL;
+		}
+	}
+
+	if (dir == LEFT) {
+		node = tree->left;
+		tree->left = unlink_end_node(tree->left, LEFT, found_node);
+		if (tree->left == NULL) {
+			tree->left = (*found_node)->right;
+			(*found_node)->left = NULL;
+			(*found_node)->right = NULL;
+		}
+	} else {
+		node = tree->right;
+		tree->right = unlink_end_node(tree->right, RIGHT, found_node);
+		if (tree->right == NULL) {
+			tree->right = (*found_node)->left;
+			(*found_node)->left = NULL;
+			(*found_node)->right = NULL;
+		}
+	}
+
+	tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+
+	return do_balance(tree);
+}
+
+static avl_node_t *avltree_insert(avl_node_t *tree, jmem_key_t key, page_t *page)
+{
+	if (tree == NULL) {
+		tree = make_avl_node(key, page);
+	} else {
+		if (key >= tree->key) {
+			tree->right = avltree_insert(tree->right, key, page);
+		} else {
+			tree->left = avltree_insert(tree->left, key, page);
+		}
+	}
+
+	tree = do_balance(tree);
+
+	tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+
+	return tree;
+}
+
+static avl_node_t *do_unlink(avl_node_t *tree)
+{
+	avl_node_t *node;
+	avl_node_t *end_node;
+	node = unlink_end_node(tree->right, LEFT, &end_node);
+	if (node) {
+		tree->right = node;
+	} else {
+		node = unlink_end_node(tree->left, RIGHT, &end_node);
+		if (node)
+			tree->left = node;
+	}
+
+	if (node == NULL) {
+		node = tree->right ? tree->right : tree->left;
+		end_node = node;
+	}
+
+	if (end_node) {
+		end_node->left = (tree->left != end_node) ? tree->left : end_node->left;
+		end_node->right = (tree->right != end_node) ? tree->right : end_node->right;
+		end_node->height =
+		    MAX(VMEM_HEIGHT(end_node->left), VMEM_HEIGHT(end_node->right)) + 1;
+	}
+
+	tree = end_node;
+
+	return tree;
+}
+
+static avl_node_t *avltree_remove(avl_node_t *tree, avl_node_t **found_node, jmem_key_t key)
+{
+	*found_node = NULL;
+	if (tree == NULL) {
+		printk(KERN_INFO "failed to find key %d\n", (int)key);
+		return NULL;
+	}
+
+	if (key == tree->key) {
+		*found_node = tree;
+		tree = do_unlink(tree);
+	} else if (key > tree->key) {
+		tree->right = avltree_remove(tree->right, found_node, key);
+	} else {
+		tree->left = avltree_remove(tree->left, found_node, key);
+	}
+
+	if (tree)
+		tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+
+	tree = do_balance(tree);
+
+	return tree;
+}
+
+void avltree_free(avl_node_t *tree)
+{
+	if (tree == NULL)
+		return;
+	if (tree->left == NULL && tree->right == NULL) {
+		VMEM_P_FREE(tree);
+		return;
+	}
+
+	avltree_free(tree->left);
+	tree->left = NULL;
+	avltree_free(tree->right);
+	tree->right = NULL;
+}
+
+static avl_node_t *remove_approx_value(avl_node_t *tree, avl_node_t **found, jmem_key_t key)
+{
+	*found = NULL;
+	if (tree == NULL) {
+		return NULL;
+	}
+
+	if (key == tree->key) {
+		*found = tree;
+		tree = do_unlink(tree);
+	} else if (key > tree->key) {
+		tree->right = remove_approx_value(tree->right, found, key);
+	} else {
+		tree->left = remove_approx_value(tree->left, found, key);
+		if (*found == NULL) {
+			*found = tree;
+			tree = do_unlink(tree);
+		}
+	}
+	if (tree)
+		tree->height = MAX(VMEM_HEIGHT(tree->left), VMEM_HEIGHT(tree->right)) + 1;
+	tree = do_balance(tree);
+
+	return tree;
+}
+
+static void set_blocks_free(jpu_mm_t *mm, int pageno, int npages)
+{
+	int last_pageno = pageno + npages - 1;
+	int i;
+	page_t *page;
+	page_t *last_page;
+
+	VMEM_ASSERT(npages);
+
+	if (last_pageno >= mm->num_pages) {
+		printk(KERN_INFO "set_blocks_free: invalid last page number: %d\n", last_pageno);
+		VMEM_ASSERT(0);
+		return;
+	}
+
+	for (i = pageno; i <= last_pageno; i++) {
+		mm->page_list[i].used = 0;
+		mm->page_list[i].alloc_pages = 0;
+		mm->page_list[i].first_pageno = -1;
+	}
+
+	page = &mm->page_list[pageno];
+	page->alloc_pages = npages;
+	last_page = &mm->page_list[last_pageno];
+	last_page->first_pageno = pageno;
+
+	mm->free_tree = avltree_insert(mm->free_tree, MAKE_KEY(npages, pageno), page);
+}
+
+static void set_blocks_alloc(jpu_mm_t *mm, int pageno, int npages)
+{
+	int last_pageno = pageno + npages - 1;
+	int i;
+	page_t *page;
+	page_t *last_page;
+
+	if (last_pageno >= mm->num_pages) {
+		printk(KERN_INFO "set_blocks_free: invalid last page number: %d\n", last_pageno);
+		VMEM_ASSERT(0);
+		return;
+	}
+
+	for (i = pageno; i <= last_pageno; i++) {
+		mm->page_list[i].used = 1;
+		mm->page_list[i].alloc_pages = 0;
+		mm->page_list[i].first_pageno = -1;
+	}
+
+	page = &mm->page_list[pageno];
+	page->alloc_pages = npages;
+
+	last_page = &mm->page_list[last_pageno];
+	last_page->first_pageno = pageno;
+
+	mm->alloc_tree = avltree_insert(mm->alloc_tree, MAKE_KEY(page->addr, 0), page);
+}
+
+int jmem_init(jpu_mm_t *mm, unsigned long addr, unsigned long size)
+{
+	int i;
+
+	mm->base_addr = (addr + (JMEM_PAGE_SIZE - 1)) & ~(JMEM_PAGE_SIZE - 1);
+	mm->mem_size = size & ~JMEM_PAGE_SIZE;
+	mm->num_pages = mm->mem_size / JMEM_PAGE_SIZE;
+	mm->page_list = (page_t *) VMEM_P_ALLOC(mm->num_pages * sizeof(page_t));
+	mm->free_tree = NULL;
+	mm->alloc_tree = NULL;
+	mm->free_page_count = mm->num_pages;
+	mm->alloc_page_count = 0;
+
+	for (i = 0; i < mm->num_pages; i++) {
+		mm->page_list[i].pageno = i;
+		mm->page_list[i].addr = mm->base_addr + i * JMEM_PAGE_SIZE;
+		mm->page_list[i].alloc_pages = 0;
+		mm->page_list[i].used = 0;
+		mm->page_list[i].first_pageno = -1;
+	}
+
+	set_blocks_free(mm, 0, mm->num_pages);
+
+	return 0;
+}
+
+int jmem_exit(jpu_mm_t *mm)
+{
+	if (mm == NULL) {
+		printk(KERN_INFO "vmem_exit: invalid handle\n");
+		return -1;
+	}
+
+	if (mm->free_tree) {
+		avltree_free(mm->free_tree);
+	}
+	if (mm->alloc_tree) {
+		avltree_free(mm->alloc_tree);
+	}
+
+	VMEM_P_FREE(mm->page_list);
+
+	mm->base_addr = 0;
+	mm->mem_size = 0;
+	mm->num_pages = 0;
+	mm->page_list = NULL;
+	mm->free_tree = NULL;
+	mm->alloc_tree = NULL;
+	mm->free_page_count = 0;
+	mm->alloc_page_count = 0;
+	return 0;
+}
+
+unsigned long jmem_alloc(jpu_mm_t *mm, int size, unsigned long pid)
+{
+	avl_node_t *node;
+	page_t *free_page;
+	int npages, free_size;
+	int alloc_pageno;
+	unsigned long ptr;
+
+	if (mm == NULL) {
+		printk(KERN_INFO "vmem_alloc: invalid handle\n");
+		return -1;
+	}
+
+	if (size <= 0)
+		return -1;
+
+	npages = (size + JMEM_PAGE_SIZE - 1) / JMEM_PAGE_SIZE;
+
+	mm->free_tree = remove_approx_value(mm->free_tree, &node, MAKE_KEY(npages, 0));
+	if (node == NULL) {
+		return -1;
+	}
+	free_page = node->page;
+	free_size = KEY_TO_VALUE(node->key);
+
+	alloc_pageno = free_page->pageno;
+	set_blocks_alloc(mm, alloc_pageno, npages);
+	if (npages != free_size) {
+		int free_pageno = alloc_pageno + npages;
+		set_blocks_free(mm, free_pageno, (free_size - npages));
+	}
+
+	VMEM_P_FREE(node);
+
+	ptr = mm->page_list[alloc_pageno].addr;
+	mm->alloc_page_count += npages;
+	mm->free_page_count -= npages;
+
+	return ptr;
+}
+
+int jmem_free(jpu_mm_t *mm, unsigned long ptr, unsigned long pid)
+{
+	unsigned long addr;
+	avl_node_t *found;
+	page_t *page;
+	int pageno, prev_free_pageno, next_free_pageno;
+	int prev_size, next_size;
+	int merge_page_no, merge_page_size, free_page_size;
+
+	if (mm == NULL) {
+		printk(KERN_INFO "vmem_free: invalid handle\n");
+		return -1;
+	}
+
+	addr = ptr;
+
+	mm->alloc_tree = avltree_remove(mm->alloc_tree, &found, MAKE_KEY(addr, 0));
+	if (found == NULL) {
+		printk(KERN_INFO "vmem_free: 0x%08x not found\n", (int)addr);
+		VMEM_ASSERT(0);
+		return -1;
+	}
+
+	/* find previous free block */
+	page = found->page;
+	pageno = page->pageno;
+	free_page_size = page->alloc_pages;
+	prev_free_pageno = pageno - 1;
+	prev_size = -1;
+	if (prev_free_pageno >= 0) {
+		if (mm->page_list[prev_free_pageno].used == 0) {
+			prev_free_pageno = mm->page_list[prev_free_pageno].first_pageno;
+			prev_size = mm->page_list[prev_free_pageno].alloc_pages;
+		}
+	}
+
+	/* find next free block */
+	next_free_pageno = pageno + page->alloc_pages;
+	next_free_pageno = (next_free_pageno == mm->num_pages) ? -1 : next_free_pageno;
+	next_size = -1;
+	if (next_free_pageno >= 0) {
+		if (mm->page_list[next_free_pageno].used == 0) {
+			next_size = mm->page_list[next_free_pageno].alloc_pages;
+		}
+	}
+	VMEM_P_FREE(found);
+
+	/* merge */
+	merge_page_no = page->pageno;
+	merge_page_size = page->alloc_pages;
+	if (prev_size >= 0) {
+		mm->free_tree =
+		    avltree_remove(mm->free_tree, &found, MAKE_KEY(prev_size, prev_free_pageno));
+		if (found == NULL) {
+			VMEM_ASSERT(0);
+			return -1;
+		}
+		merge_page_no = found->page->pageno;
+		merge_page_size += found->page->alloc_pages;
+		VMEM_P_FREE(found);
+	}
+	if (next_size >= 0) {
+		mm->free_tree =
+		    avltree_remove(mm->free_tree, &found, MAKE_KEY(next_size, next_free_pageno));
+		if (found == NULL) {
+			VMEM_ASSERT(0);
+			return -1;
+		}
+		merge_page_size += found->page->alloc_pages;
+		VMEM_P_FREE(found);
+	}
+
+	page->alloc_pages = 0;
+	page->first_pageno = -1;
+
+	set_blocks_free(mm, merge_page_no, merge_page_size);
+
+	mm->alloc_page_count -= free_page_size;
+	mm->free_page_count += free_page_size;
+
+	return 0;
+}
+
+#endif /* __CNM_JPU_MM_H__ */
diff --git a/drivers/soc/spacemit/jpu/jpu.c b/drivers/soc/spacemit/jpu/jpu.c
new file mode 100644
index 000000000000..3dbdb7b38e2d
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jpu.c
@@ -0,0 +1,1803 @@
+// SPDX-License-Identifier: GPL-2.0
+
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/wait.h>
+#include <linux/list.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/delay.h>
+#include <linux/uaccess.h>
+#include <linux/cdev.h>
+#include <linux/slab.h>
+//#include <linux/sched.h>
+#include <linux/sched/signal.h>
+#include <linux/pm_runtime.h>
+#include <asm/io.h>
+#include <linux/pm_qos.h>
+#include <linux/clk.h>
+#include <linux/reset.h>
+#include "jpuconfig.h"
+#include "regdefine.h"
+#include "jpu.h"
+#include "jpu_export.h"
+
+#define JPU_TBU_BASE_VA (0x80000000)
+#define JPU_TBU_VA_STEP (0x2000000)
+#define DDR_QOS_ENABLE
+#ifdef ENABLE_DEBUG_MSG
+#define JLOG(dev, fmt, args...) dev_info(dev, "JPU: " fmt,  ## args);
+#else
+#define JLOG(args...)
+#endif
+jpu_dma_buf_info buf_inf[2];
+#if defined (CONFIG_PM) && defined (DDR_QOS_ENABLE)
+//static struct freq_qos_request jpu_ddrfreq_qos_rreq_sum;
+//static struct freq_qos_request jpu_ddrfreq_qos_wreq_sum;
+#endif
+typedef struct jpu_drv_context_t {
+	struct fasync_struct *async_queue;
+	u32 open_count;
+	u32 interrupt_reason[MAX_NUM_INSTANCE];
+} jpu_drv_context_t;
+
+enum spacemit_iommu_type {
+	TBU_INPUT = 0,
+	TBU_OUTPUT = 1,
+};
+
+typedef struct jpudrv_buffer_pool_t {
+	struct list_head list;
+	struct jpudrv_buffer_t jb;
+	struct file *filp;
+} jpudrv_buffer_pool_t;
+
+typedef struct jpudrv_instance_list_t {
+	struct list_head list;
+	unsigned long inst_idx;
+	struct file *filp;
+} jpudrv_instance_list_t;
+
+typedef struct jpudrv_instance_pool_t {
+	unsigned char codecInstPool[MAX_NUM_INSTANCE][MAX_INST_HANDLE_SIZE];
+} jpudrv_instance_pool_t;
+
+struct jpu_device {
+	struct device *jdev;
+
+	struct device *jpu_device;
+	struct cdev s_jpu_cdev;
+	struct class *jpu_class;
+	dev_t s_jpu_major;
+
+	jpudrv_buffer_t s_instance_pool;
+	jpu_drv_context_t s_jpu_drv_context;
+
+	int s_jpu_open_ref_count;
+	int s_jpu_irq;
+
+	struct clk *cclk;
+	atomic_t cclk_enable_count;
+	int32_t cclk_max_frequency;
+	int32_t cclk_min_frequency;
+	int32_t cclk_cur_frequency;
+	int32_t cclk_default_frequency;
+	struct clk *aclk;
+	atomic_t aclk_enable_count;
+	int64_t aclk_max_frequency;
+	int32_t aclk_min_frequency;
+	int32_t aclk_cur_frequency;
+	int32_t aclk_default_frequency;
+
+	struct clk *iclk;
+	atomic_t iclk_enable_count;
+	int64_t iclk_max_frequency;
+	int32_t iclk_min_frequency;
+	int32_t iclk_cur_frequency;
+	int32_t iclk_default_frequency;
+
+	struct reset_control *jpg_reset;
+	atomic_t jpg_reset_enable_count;
+
+	struct reset_control *lcd_mclk_reset;
+	atomic_t lcd_mclk_reset_enable_count;
+
+	struct reset_control *isp_ci_reset;
+	atomic_t isp_ci_reset_enable_count;
+
+	struct reset_control *freset;
+	atomic_t freset_enable_count;
+
+	struct reset_control *sreset;
+	atomic_t sreset_enable_count;
+
+	jpudrv_buffer_t s_jpu_register;
+	void __iomem *reg;
+
+	int s_interrupt_flag[MAX_NUM_INSTANCE];
+	wait_queue_head_t s_interrupt_wait_q[MAX_NUM_INSTANCE];
+
+	spinlock_t s_jpu_lock;
+	struct semaphore s_jpu_sem;
+	struct list_head s_jbp_head;
+	struct list_head s_inst_list_head;
+	u32 time_out_cycs;
+	u32 page_size;
+	u64 va_base;
+	u64 va_end;
+	struct tbu_instance tbu_ins[TBU_INSTANCES_NUM];
+	unsigned long tbu_ins_bitmap;
+	spinlock_t tbu_ins_bitmap_lock;
+	int tbu_ins_map;
+	bool is_hw_enable;
+	spinlock_t hw_access_lock;
+	struct semaphore tbu_ins_free_cnt;
+#ifdef CONFIG_PM
+#ifdef DDR_QOS_ENABLE
+	struct freq_constraints *ddr_qos_cons;
+	struct freq_qos_request *ddr_qos_rreq;
+	struct freq_qos_request *ddr_qos_wreq;
+#endif
+#endif
+};
+
+static void jpu_writel(struct jpu_device *dev, int offset, u32 val)
+{
+	writel(val, dev->reg + offset);
+}
+
+static u32 jpu_readl(struct jpu_device *dev, int offset)
+{
+	return readl(dev->reg + offset);
+}
+
+static void jpu_set_reg_bits(struct jpu_device *dev, u64 offset, u32 bits)
+{
+	jpu_writel(dev, offset, (jpu_readl(dev, offset) | bits));
+}
+
+static void jpu_clear_reg_bits(struct jpu_device *dev, u64 offset, u32 bits)
+{
+	jpu_writel(dev, offset, (jpu_readl(dev, offset) & ~bits));
+}
+
+static int jpu_jpg_reset_deassert(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->freset)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->jpg_reset_enable_count);
+	JLOG(jdev->jdev, "deassert jpg_reset\n");
+	return reset_control_deassert(jdev->jpg_reset);
+}
+
+static int jpu_lcd_mclk_reset_deassert(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->lcd_mclk_reset)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->lcd_mclk_reset_enable_count);
+	JLOG(jdev->jdev, "deassert lcd_mclk_reset\n");
+	return reset_control_deassert(jdev->lcd_mclk_reset);
+}
+
+static int jpu_isp_ci_reset_deassert(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->isp_ci_reset)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->isp_ci_reset_enable_count);
+	JLOG(jdev->jdev, "deassert isp_ci_reset\n");
+	return reset_control_deassert(jdev->isp_ci_reset);
+}
+
+static int jpu_freset_deassert(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->freset)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->freset_enable_count);
+	JLOG(jdev->jdev, "deassert freset\n");
+	return reset_control_deassert(jdev->freset);
+}
+
+static int jpu_sreset_deassert(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->sreset)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->sreset_enable_count);
+	JLOG(jdev->jdev, "deassert sreset\n");
+	return reset_control_deassert(jdev->sreset);
+}
+
+static void jpu_jpg_reset_assert(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->jpg_reset)
+	    && atomic_read(&jdev->jpg_reset_enable_count) >= 1) {
+		JLOG(jdev->jdev, "assert jpg_reset\n");
+		atomic_dec(&jdev->jpg_reset_enable_count);
+		reset_control_assert(jdev->jpg_reset);
+	}
+}
+
+static void jpu_lcd_mclk_reset_assert(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->lcd_mclk_reset)
+	    && atomic_read(&jdev->lcd_mclk_reset_enable_count) >= 1) {
+		JLOG(jdev->jdev, "assert lcd_mclk_reset\n");
+		atomic_dec(&jdev->lcd_mclk_reset_enable_count);
+		reset_control_assert(jdev->lcd_mclk_reset);
+	}
+}
+
+static void jpu_isp_ci_reset_assert(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->isp_ci_reset)
+	    && atomic_read(&jdev->isp_ci_reset_enable_count) >= 1) {
+		JLOG(jdev->jdev, "assert isp_ci_reset\n");
+		atomic_dec(&jdev->isp_ci_reset_enable_count);
+		reset_control_assert(jdev->isp_ci_reset);
+	}
+}
+
+static void jpu_freset_assert(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->freset)
+	    && atomic_read(&jdev->freset_enable_count) >= 1) {
+		JLOG(jdev->jdev, "assert freset\n");
+		atomic_dec(&jdev->freset_enable_count);
+		reset_control_assert(jdev->freset);
+	}
+}
+
+static void jpu_sreset_assert(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->sreset)
+	    && atomic_read(&jdev->sreset_enable_count) >= 1) {
+		JLOG(jdev->jdev, "assert sreset\n");
+		atomic_dec(&jdev->sreset_enable_count);
+		reset_control_assert(jdev->sreset);
+	}
+}
+
+
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+static int jpu_aclk_enable(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->aclk)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->aclk_enable_count);
+	JLOG(jdev->jdev, "enable aclk\n");
+	return clk_prepare_enable(jdev->aclk);
+}
+
+static int jpu_iclk_enable(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->iclk)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->iclk_enable_count);
+	JLOG(jdev->jdev, "enable iclk\n");
+	return clk_prepare_enable(jdev->iclk);
+}
+
+static int jpu_cclk_enable(struct jpu_device *jdev)
+{
+	if (IS_ERR_OR_NULL(jdev->cclk)) {
+		return -EINVAL;
+	}
+	atomic_inc(&jdev->cclk_enable_count);
+	JLOG(jdev->jdev, "enable cclk\n");
+	return clk_prepare_enable(jdev->cclk);
+}
+
+static void jpu_aclk_disable(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->aclk) && __clk_is_enabled(jdev->aclk)
+	    && atomic_read(&jdev->aclk_enable_count) >= 1) {
+		JLOG(jdev->jdev, "disable aclk\n");
+		atomic_dec(&jdev->aclk_enable_count);
+		clk_disable_unprepare(jdev->aclk);
+	}
+}
+
+static void jpu_cclk_disable(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->cclk) && __clk_is_enabled(jdev->cclk)
+	    && atomic_read(&jdev->cclk_enable_count) >= 1) {
+		JLOG(jdev->jdev, "disable cclk\n");
+		atomic_dec(&jdev->cclk_enable_count);
+		clk_disable_unprepare(jdev->cclk);
+	}
+}
+
+static void jpu_iclk_disable(struct jpu_device *jdev)
+{
+	if (!IS_ERR_OR_NULL(jdev->iclk) && __clk_is_enabled(jdev->iclk)
+	    && atomic_read(&jdev->iclk_enable_count) >= 1) {
+		JLOG(jdev->jdev, "disable iclk\n");
+		atomic_dec(&jdev->iclk_enable_count);
+		clk_disable_unprepare(jdev->iclk);
+	}
+}
+
+static int jpu_clk_enable(struct jpu_device *jdev)
+{
+	int ret;
+#if 0
+	ret = clk_set_rate(jdev->aclk, jdev->aclk_cur_frequency);
+	if (ret) {
+		return ret;
+	}
+#endif
+
+#if 0
+	ret = clk_set_rate(jdev->cclk, jdev->cclk_cur_frequency);
+	if (ret) {
+		return ret;
+	}
+#endif
+
+	ret = jpu_cclk_enable(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_aclk_enable(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_iclk_enable(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_jpg_reset_deassert(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_lcd_mclk_reset_deassert(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_isp_ci_reset_deassert(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_freset_deassert(jdev);
+	if (ret) {
+		return ret;
+	}
+	ret = jpu_sreset_deassert(jdev);
+	if (ret) {
+		return ret;
+	}
+
+	return ret;
+}
+
+static void jpu_clk_disable(struct jpu_device *jdev)
+{
+	jpu_cclk_disable(jdev);
+	jpu_aclk_disable(jdev);
+	jpu_iclk_disable(jdev);
+	jpu_jpg_reset_assert(jdev);
+	jpu_lcd_mclk_reset_assert(jdev);
+	jpu_isp_ci_reset_assert(jdev);
+	jpu_freset_assert(jdev);
+	jpu_sreset_assert(jdev);
+}
+
+static int jpu_hw_reset(struct jpu_device *jdev)
+{
+	JLOG(jdev->jdev, "request jpu reset from application.\n");
+
+	jpu_cclk_disable(jdev);
+	jpu_aclk_disable(jdev);
+	jpu_iclk_disable(jdev);
+	jpu_jpg_reset_assert(jdev);
+	jpu_lcd_mclk_reset_assert(jdev);
+	jpu_isp_ci_reset_assert(jdev);
+	jpu_freset_assert(jdev);
+	jpu_sreset_assert(jdev);
+
+	return 0;
+}
+#endif
+
+static int jpu_enable_jpu_mmu_hw(struct jpu_device *jpu_device)
+{
+	int i;
+	struct tbu_instance *tbu;
+
+	for (i = 0; i < TBU_INSTANCES_NUM; i++) {
+		tbu = &jpu_device->tbu_ins[i];
+		tbu->ttb_size = 0;
+		tbu->always_preload = false;
+		tbu->enable_preload = true;
+		tbu->nsaid = 0;
+		tbu->qos = 2;
+		tbu->secure_enable = false;
+	}
+	jpu_device->tbu_ins_map = -1;
+	//jpu_device->tbu_ins_bitmap = 0;
+	sema_init(&jpu_device->tbu_ins_free_cnt, TBU_INSTANCES_NUM);
+
+	/* Set MJPEG_MMU iova base */
+	jpu_writel(jpu_device, MJPEG_MMU_BVA_LO, jpu_device->va_base & 0xFFFFFFFF);
+	jpu_writel(jpu_device, MJPEG_MMU_BVA_HI, jpu_device->va_base >> 32);
+
+	/* Set MJPEG_MMU timeout cycles */
+	jpu_writel(jpu_device, MJPEG_MMU_TIMEOUT_VALUE, jpu_device->time_out_cycs);
+
+	/* Enable MJPEG_MMU irq */
+	jpu_set_reg_bits(jpu_device, MJPEG_MMU_IRQ_ENABLE, 0);
+
+	jpu_device->is_hw_enable = true;
+	return 0;
+}
+
+static void jpu_disable_jpu_mmu_hw(struct jpu_device *jpu_device)
+{
+	int i;
+	struct tbu_instance *tbu;
+
+	/* Waiting for post done. */
+	spin_lock(&jpu_device->hw_access_lock);
+	jpu_device->is_hw_enable = false;
+	spin_unlock(&jpu_device->hw_access_lock);
+
+	for (i = 0; i < TBU_INSTANCES_NUM; i++) {
+		tbu = &jpu_device->tbu_ins[i];
+		tbu->ttb_size = 0;
+	}
+	/* Disable all TBUs. */
+	for (i = 0; i < TBU_NUM; i++)
+		jpu_writel(jpu_device, MJPEG_MMU_TCR0_BASE + MJPEG_MMU_TBUx_STEP * i, 0);
+
+	/* Disable MJPEG_MMU irq. */
+	jpu_clear_reg_bits(jpu_device, MJPEG_MMU_IRQ_ENABLE, 0x1FF);
+
+}
+
+static void jpu_write_tbu_table(struct jpu_device *jpu_device, struct tbu_instance *tbu,
+				unsigned long iova, phys_addr_t paddr, size_t size)
+{
+	u32 *ttb_entry;
+	uint64_t mask = 0;
+	uint32_t val;
+
+	mask = (jpu_device->page_size == 4096) ? 0xFFFFFFFFFFFFF000 : 0xFFFFFFFFFFFF0000;
+	ttb_entry = tbu->ttb_va + (iova - tbu->va_base) / jpu_device->page_size;
+	while (size != 0) {
+		paddr = paddr & 0xFFFFFFFF;
+		val = ((paddr & mask) >> TTB_ENTRY_SHIFT) & 0x1FFFFF;
+		*ttb_entry = val;
+		size -= jpu_device->page_size;
+		ttb_entry++;
+		paddr += jpu_device->page_size;
+	}
+}
+
+static void jpu_mmu_post(struct jpu_device *jpu_device, int *ins_id, int num)
+{
+	u32 reg;
+	struct tbu_instance *tbu;
+	int i, tbu_slot[TBU_NUM];
+
+	for (i = 0; i < TBU_NUM; i++)
+		tbu_slot[i] = -1;
+
+	for (i = 0; i < num; i++) {
+		int index;
+		tbu = &jpu_device->tbu_ins[ins_id[i]];
+		index = (tbu->va_base - jpu_device->va_base) / VA_STEP_PER_TBU;
+		tbu_slot[index] = ins_id[i];
+	}
+
+	spin_lock(&jpu_device->hw_access_lock);
+	if (!jpu_device->is_hw_enable) {
+		spin_unlock(&jpu_device->hw_access_lock);
+		return;
+	}
+
+	for (i = 0; i < TBU_NUM; i++) {
+		if (tbu_slot[i] != -1) {
+			tbu = &jpu_device->tbu_ins[tbu_slot[i]];
+			if (tbu->ttb_size == 0) {
+				jpu_writel(jpu_device,
+					   MJPEG_MMU_TCR0_BASE + i * MJPEG_MMU_TBUx_STEP, 0);
+			} else {
+				jpu_writel(jpu_device,
+					   MJPEG_MMU_TTBLR_BASE +
+					   i * MJPEG_MMU_TBUx_STEP, tbu->ttb_pa & 0xFFFFFFFF);
+				jpu_writel(jpu_device,
+					   MJPEG_MMU_TTBHR_BASE +
+					   i * MJPEG_MMU_TBUx_STEP, tbu->ttb_pa >> 32);
+
+				reg = (tbu->ttb_size - 1) << 16;
+				if (tbu->always_preload)
+					reg |= BIT(3);
+				if (tbu->enable_preload)
+					reg |= BIT(2);
+				if (jpu_device->page_size == SZ_64K)
+					reg |= BIT(1);
+				reg |= BIT(0);
+				jpu_writel(jpu_device,
+					   MJPEG_MMU_TCR0_BASE + i * MJPEG_MMU_TBUx_STEP, reg);
+			}
+		}
+	}
+	spin_unlock(&jpu_device->hw_access_lock);
+}
+
+static int jpu_mmu_map_sg(struct jpu_device *jpu_device, unsigned long iova,
+			  struct scatterlist *sg, unsigned int nents, size_t *mapped,
+			  u32 data_size, u32 append_buf_size, u32 need_append)
+{
+	struct tbu_instance *tbu;
+	struct scatterlist *s;
+	unsigned int i;
+	unsigned int j;
+	phys_addr_t paddr;
+	size_t size;
+	unsigned long orig_iova = iova;
+	unsigned int offset = 0;
+	unsigned int find = 0;
+	unsigned int bottom_buf_size = 0;
+
+	int invaild_data_size = data_size - append_buf_size;
+	if ((iova >= jpu_device->va_end) && (nents == 1))
+		return sg->length;
+
+	jpu_device->tbu_ins_map = (iova - BASE_VIRTUAL_ADDRESS) / VA_STEP_PER_TBU;
+
+	if (jpu_device->tbu_ins_map < 0 || jpu_device->tbu_ins_map >= TBU_INSTANCES_NUM)
+		goto out_id_err;
+	tbu = &jpu_device->tbu_ins[jpu_device->tbu_ins_map];
+
+	if (tbu->ttb_size == 0) {
+		int index;
+		if (iova < jpu_device->va_base || iova >= jpu_device->va_end)
+			goto out_iova_err;
+		index = (iova - jpu_device->va_base) / VA_STEP_PER_TBU;
+		tbu->va_base = jpu_device->va_base + index * VA_STEP_PER_TBU;
+		tbu->va_end = tbu->va_base + VA_STEP_PER_TBU;
+	}
+
+	if (iova < tbu->va_base || iova >= tbu->va_end)
+		goto out_iova_err;
+	if (append_buf_size && need_append) {
+		for_each_sg(sg, s, nents, i) {
+			paddr = page_to_phys(sg_page(s)) + s->offset;
+			size = s->length;
+			if (!IS_ALIGNED(s->offset, jpu_device->page_size)) {
+				dev_warn(jpu_device->jdev,
+					 "paddr not aligned: iova %lx, paddr %llx, size %lx\n",
+					 iova, paddr, size);
+				goto out_region_err;
+			}
+			invaild_data_size -= size;
+			if (invaild_data_size < 0) {
+				if (!find) {
+					find = 1;
+				}
+				if (find) {
+					bottom_buf_size += size;
+				}
+				if (iova + size > tbu->va_end || size == 0)
+					goto out_region_err;
+				jpu_write_tbu_table(jpu_device, tbu, iova, paddr, size);
+				iova += size;
+			}
+		}
+		if (append_buf_size)
+			offset = bottom_buf_size - append_buf_size;
+	}
+	for_each_sg(sg, s, nents, j) {
+		paddr = page_to_phys(sg_page(s)) + s->offset;
+		size = s->length;
+		if (!IS_ALIGNED(s->offset, jpu_device->page_size)) {
+			dev_warn(jpu_device->jdev,
+				 "paddr not aligned: iova %lx, paddr %llx, size %lx\n",
+				 iova, paddr, size);
+			goto out_region_err;
+		}
+		if (iova + size > tbu->va_end || size == 0)
+			goto out_region_err;
+
+		jpu_write_tbu_table(jpu_device, tbu, iova, paddr, size);
+		iova += size;
+	}
+
+	if (iova > tbu->va_base + jpu_device->page_size * tbu->ttb_size)
+		tbu->ttb_size = (iova - tbu->va_base) / jpu_device->page_size;
+
+	*mapped = iova - orig_iova;
+
+	jpu_mmu_post(jpu_device, &jpu_device->tbu_ins_map, 1);
+	return offset;
+
+out_region_err:
+	dev_err(jpu_device->jdev, "Map_sg is wrong: iova %lx, paddr %llx, size %lx\n",
+		iova, paddr, size);
+	return 0;
+out_iova_err:
+	dev_err(jpu_device->jdev, "Map_sg is wrong: iova %lx", iova);
+	return 0;
+out_id_err:
+	dev_err(jpu_device->jdev, "TBU ins_id is wrong: %d\n", jpu_device->tbu_ins_map);
+	return 0;
+}
+
+static dma_addr_t get_addr_from_fd(struct jpu_device *jpu_dev, int fd,
+				   struct jpu_dma_buf_info *pInfo, u32 data_size,
+				   u32 append_buf_size)
+{
+	struct device *dev = jpu_dev->jdev;
+	struct sg_table *sgt;
+	dma_addr_t addr;
+	int offset = 0;
+	size_t mapped_size = 0;
+	u32 need_append = 0;
+
+	pInfo->buf_fd = fd;
+	pInfo->dmabuf = dma_buf_get(fd);
+	if (IS_ERR(pInfo->dmabuf)) {
+		pr_err("jpu get dmabuf fail fd:%d\n", fd);
+		return 0;
+	}
+	pInfo->attach = dma_buf_attach(pInfo->dmabuf, dev);
+	if (IS_ERR(pInfo->attach)) {
+		pr_err("jpu get dma buf attach fail\n");
+		goto err_dmabuf_put;
+	}
+	pInfo->sgtable = dma_buf_map_attachment(pInfo->attach, DMA_BIDIRECTIONAL);
+	if (IS_ERR(pInfo->sgtable)) {
+		pr_err("jpu get dma buf map attachment fail\n");
+		goto err_dmabuf_detach;
+	}
+	sgt = pInfo->sgtable;
+	if (sgt->nents == 1) {
+		addr = sg_dma_address(sgt->sgl);
+	} else {
+		if (!jpu_dev->is_hw_enable)
+			jpu_enable_jpu_mmu_hw(jpu_dev);
+		addr = JPU_TBU_BASE_VA + (pInfo->tbu_id) * JPU_TBU_VA_STEP;
+		if (pInfo->tbu_id == TBU_INPUT) {
+			need_append = 1;
+		}
+		offset =
+		    jpu_mmu_map_sg(jpu_dev, addr, sgt->sgl, sgt->nents, &mapped_size,
+				   data_size, append_buf_size, need_append);
+		if (!mapped_size) {
+			pr_err("jpu iommu map sgtable fail\n");
+			goto err_dmabuf_unmap;
+		}
+	}
+	return addr + offset;
+err_dmabuf_unmap:
+	dma_buf_unmap_attachment(pInfo->attach, pInfo->sgtable, DMA_BIDIRECTIONAL);
+err_dmabuf_detach:
+	dma_buf_detach(pInfo->dmabuf, pInfo->attach);
+err_dmabuf_put:
+	dma_buf_put(pInfo->dmabuf);
+	return 0;
+}
+
+static int jpu_alloc_dma_buffer(struct jpu_device *jdev, jpudrv_buffer_t *jb)
+{
+	if (!jb) {
+		return -EINVAL;
+	}
+
+	jb->base = (unsigned long)dma_alloc_coherent(jdev->jdev, PAGE_ALIGN(jb->size),
+						     (dma_addr_t *) (&jb->phys_addr),
+						     GFP_DMA | GFP_KERNEL);
+	if ((void *)(jb->base) == NULL) {
+		dev_err(jdev->jdev, "Physical memory allocation error size=%d\n", jb->size);
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void jpu_free_dma_buffer(struct jpu_device *jdev, jpudrv_buffer_t *jb)
+{
+	if (!jb) {
+		return;
+	}
+
+	if (jb->base) {
+		dma_free_coherent(jdev->jdev, PAGE_ALIGN(jb->size), (void *)jb->base,
+				  jb->phys_addr);
+	}
+}
+
+static int jpu_free_instances(struct file *filp)
+{
+	struct jpu_device *jdev = filp->private_data;
+	jpudrv_instance_list_t *vil, *n;
+	jpudrv_instance_pool_t *vip;
+	void *vip_base;
+	int instance_pool_size_per_core;
+	void *jdi_mutexes_base;
+	const int PTHREAD_MUTEX_T_DESTROY_VALUE = 0xdead10cc;
+
+	JLOG(jdev->jdev, "free instance\n");
+
+	// s_instance_pool.size  assigned to the size of all core once call JDI_IOCTL_GET_INSTANCE_POOL by user.
+	instance_pool_size_per_core = (jdev->s_instance_pool.size / MAX_NUM_JPU_CORE);
+
+	list_for_each_entry_safe(vil, n, &jdev->s_inst_list_head, list) {
+		if (vil->filp == filp) {
+			vip_base =
+			    (void *)(jdev->s_instance_pool.base + instance_pool_size_per_core);
+			JLOG(jdev->jdev,
+			     "jpu_free_instances detect instance crash instIdx=%d, vip_base=%p, instance_pool_size_per_core=%d\n",
+			     (int)vil->inst_idx, vip_base, (int)instance_pool_size_per_core);
+			vip = (jpudrv_instance_pool_t *) vip_base;
+			if (vip) {
+				// only first 4 byte is key point(inUse of CodecInst in jpuapi) to free the corresponding instance
+				memset(&vip->codecInstPool[vil->inst_idx], 0x00, 4);
+#define PTHREAD_MUTEX_T_HANDLE_SIZE 4
+				jdi_mutexes_base =
+				    (vip_base + (instance_pool_size_per_core - PTHREAD_MUTEX_T_HANDLE_SIZE * 4));
+				JLOG(jdev->jdev,
+				     "force to destroy jdi_mutexes_base=%p in userspace \n", jdi_mutexes_base);
+				if (jdi_mutexes_base) {
+					int i;
+					for (i = 0; i < 4; i++) {
+						memcpy(jdi_mutexes_base,
+						       &PTHREAD_MUTEX_T_DESTROY_VALUE, PTHREAD_MUTEX_T_HANDLE_SIZE);
+						jdi_mutexes_base += PTHREAD_MUTEX_T_HANDLE_SIZE;
+					}
+				}
+			}
+
+			jdev->s_jpu_open_ref_count--;
+			list_del(&vil->list);
+			kfree(vil);
+		}
+	}
+
+	return 0;
+}
+
+static int jpu_free_buffers(struct file *filp)
+{
+	struct jpu_device *jdev = filp->private_data;
+	jpudrv_buffer_pool_t *pool, *n;
+	jpudrv_buffer_t jb;
+
+	JLOG(jdev->jdev, "jpu free buffers\n");
+
+	list_for_each_entry_safe(pool, n, &jdev->s_jbp_head, list) {
+		if (pool->filp == filp) {
+			jb = pool->jb;
+			if (jb.base) {
+				jpu_free_dma_buffer(jdev, &jb);
+				list_del(&pool->list);
+				kfree(pool);
+			}
+		}
+	}
+
+	return 0;
+}
+
+static irqreturn_t jpu_irq_handler(int irq, void *dev_id)
+{
+	struct jpu_device *jdev = (struct jpu_device *)dev_id;
+	jpu_drv_context_t *dev = &jdev->s_jpu_drv_context;
+	int i = 0;
+	unsigned long flags;
+	u32 int_reason;
+	u64 last_va, last_pa;
+	u32 mmu_irq_status;
+	u32 reg;
+	int j;
+
+	spin_lock_irqsave(&jdev->s_jpu_lock, flags);
+	// suppose instance 0 irq handle
+	int_reason = jpu_readl(jdev, MJPEG_PIC_STATUS_REG);
+	if (int_reason != 0) {
+		jdev->s_interrupt_flag[i] = 1;
+		if (int_reason & (1 << INT_JPU_DONE)) {
+			jpu_writel(jdev, MJPEG_BBC_FLUSH_CMD_REG, 0);
+		}
+		jpu_writel(jdev, MJPEG_PIC_STATUS_REG, int_reason);	// clear JPEG register
+	}
+	mmu_irq_status = jpu_readl(jdev, MJPEG_MMU_IRQ_STATUS);
+
+	if (mmu_irq_status != 0) {
+		reg = jpu_readl(jdev, MJPEG_MMU_LAST_PA_ADDR_HI);
+		last_pa = reg & 0x1;
+		reg = jpu_readl(jdev, MJPEG_MMU_LAST_PA_ADDR_LO);
+		last_pa = (last_pa << 32) | reg;
+		reg = jpu_readl(jdev, MJPEG_MMU_LAST_VA_ADDR_HI);
+		last_va = reg & 0x1;
+		reg = jpu_readl(jdev, MJPEG_MMU_LAST_VA_ADDR_LO);
+		last_va = (last_va << 32) | reg;
+
+		/* Print IRQ status. */
+		dev_err_ratelimited(jdev->jdev,
+				    "Unexpected fault: IRQ status 0x%x, last PA 0x%09llx, last VA 0x%09llx\n",
+				    mmu_irq_status, last_pa, last_va);
+
+		if (mmu_irq_status & BIT(8)) {
+			u64 timeout_va_addr;
+			reg = jpu_readl(jdev, MJPEG_MMU_TIMEOUT_VA_ADDR_HI);
+			timeout_va_addr = reg & 0x1;
+			reg = jpu_readl(jdev, MJPEG_MMU_TIMEOUT_VA_ADDR_LO);
+			timeout_va_addr = (timeout_va_addr << 32) | reg;
+			dev_err_ratelimited(jdev->jdev,
+					    "timeout error: timeout_va 0x%09llx\n",
+					    timeout_va_addr);
+		}
+
+		for (j = 0; j < TBU_NUM; j++) {
+			if (mmu_irq_status & BIT(i)) {
+				reg = jpu_readl(jdev, MJPEG_MMU_TBU_STATUS_BASE + j * MJPEG_MMU_TBUx_STEP);
+				dev_err_ratelimited(jdev->jdev,
+						    "TBU%d error: read addr 0x%08x, write addr 0x%08x\n",
+						    j, ((reg >> 16) & 0xFFF), reg & 0x1FFF);
+			}
+		}
+
+		/* clear DMA error */
+		if (mmu_irq_status & 0xFF)
+			jpu_set_reg_bits(jdev, MJPEG_MMU_ERROR_CLEAR, BIT(1));
+
+		/* reset IRQ status */
+		jpu_writel(jdev, MJPEG_MMU_IRQ_STATUS, mmu_irq_status);
+	}
+	dev->interrupt_reason[i] = int_reason;
+	spin_unlock_irqrestore(&jdev->s_jpu_lock, flags);
+
+	JLOG(jdev->jdev, "JPU: instance no %d, INTERRUPT FLAG: %08x, %08x\n",
+	     i, dev->interrupt_reason[i], MJPEG_PIC_STATUS_REG);
+
+	if (dev->async_queue)
+		kill_fasync(&dev->async_queue, SIGIO, POLL_IN);	// notify the interrupt to userspace
+
+	wake_up_interruptible(&jdev->s_interrupt_wait_q[i]);
+	return IRQ_HANDLED;
+}
+
+static int jpu_open(struct inode *inode, struct file *filp)
+{
+	struct jpu_device *jdev = container_of(inode->i_cdev, struct jpu_device, s_jpu_cdev);
+
+	spin_lock(&jdev->s_jpu_lock);
+
+	if (jdev->s_jpu_drv_context.open_count) {
+		spin_unlock(&jdev->s_jpu_lock);
+		return -EBUSY;
+	} else {
+		jdev->s_jpu_drv_context.open_count++;
+	}
+
+	filp->private_data = jdev;
+	spin_unlock(&jdev->s_jpu_lock);
+	pm_runtime_get_sync(jdev->jdev);
+	return 0;
+}
+
+static ssize_t jpu_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos)
+{
+	return 0;
+}
+
+static ssize_t jpu_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos)
+{
+	return 0;
+}
+
+static long jpu_ioctl(struct file *filp, u_int cmd, u_long arg)
+{
+	struct jpu_device *jdev = filp->private_data;
+	jpudrv_buffer_pool_t *jbp, *n;
+	jpudrv_buffer_t jb;
+	jpudrv_intr_info_t info;
+	jpudrv_inst_info_t inst_info;
+	struct jpu_drv_context_t *dev_ctx;
+	u32 instance_no;
+	JPU_DMA_CFG cfg;
+	int i;
+	struct dma_buf *dmabuf;
+	struct dma_buf_attachment *attach;
+	struct sg_table *sg_table;
+	jpu_dma_buf_info pInfo;
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+	u32 clkgate;
+#endif
+	int ret = 0;
+
+	switch (cmd) {
+	case JDI_IOCTL_ALLOCATE_PHYSICAL_MEMORY:
+		ret = down_interruptible(&jdev->s_jpu_sem);
+		if (ret) {
+			return -EAGAIN;
+		}
+
+		jbp = kzalloc(sizeof(jpudrv_buffer_pool_t), GFP_KERNEL);
+		if (!jbp) {
+			up(&jdev->s_jpu_sem);
+			return -ENOMEM;
+		}
+
+		ret = copy_from_user(&(jbp->jb), (jpudrv_buffer_t *) arg, sizeof(jpudrv_buffer_t));
+		if (ret) {
+			kfree(jbp);
+			up(&jdev->s_jpu_sem);
+			return -EFAULT;
+		}
+
+		ret = jpu_alloc_dma_buffer(jdev, &(jbp->jb));
+		if (ret) {
+			kfree(jbp);
+			up(&jdev->s_jpu_sem);
+			return -ENOMEM;
+		}
+
+		ret = copy_to_user((void __user *)arg, &(jbp->jb), sizeof(jpudrv_buffer_t));
+		if (ret) {
+			kfree(jbp);
+			up(&jdev->s_jpu_sem);
+			return -EFAULT;
+		}
+
+		jbp->filp = filp;
+
+		spin_lock(&jdev->s_jpu_lock);
+		list_add(&jbp->list, &jdev->s_jbp_head);
+		spin_unlock(&jdev->s_jpu_lock);
+
+		up(&jdev->s_jpu_sem);
+
+		break;
+	case JDI_IOCTL_FREE_PHYSICALMEMORY:
+		ret = down_interruptible(&jdev->s_jpu_sem);
+		if (ret) {
+			return -EAGAIN;
+		}
+
+		ret = copy_from_user(&jb, (jpudrv_buffer_t *) arg, sizeof(jpudrv_buffer_t));
+		if (ret) {
+			up(&jdev->s_jpu_sem);
+			return -EACCES;
+		}
+
+		if (jb.base) {
+			jpu_free_dma_buffer(jdev, &jb);
+		}
+
+		spin_lock(&jdev->s_jpu_lock);
+
+		list_for_each_entry_safe(jbp, n, &jdev->s_jbp_head, list) {
+			if (jbp->jb.base == jb.base) {
+				list_del(&jbp->list);
+				kfree(jbp);
+				break;
+			}
+		}
+
+		spin_unlock(&jdev->s_jpu_lock);
+
+		up(&jdev->s_jpu_sem);
+
+		break;
+	case JDI_IOCTL_GET_RESERVED_VIDEO_MEMORY_INFO:
+		ret = -EFAULT;
+		break;
+	case JDI_IOCTL_WAIT_INTERRUPT:
+		dev_ctx = &jdev->s_jpu_drv_context;
+		ret = copy_from_user(&info, (jpudrv_intr_info_t *) arg, sizeof(jpudrv_intr_info_t));
+		if (ret) {
+			return -EFAULT;
+		}
+
+		instance_no = info.inst_idx;
+		ret =
+		    wait_event_interruptible_timeout(jdev->s_interrupt_wait_q[instance_no],
+						     jdev->s_interrupt_flag[instance_no] != 0,
+						     msecs_to_jiffies(info.timeout));
+		if (!ret) {
+			dev_err(jdev->jdev,
+				"instance no %d ETIME, s_interrupt_flag(%d), reason(0x%08x)\n",
+				instance_no, jdev->s_interrupt_flag[instance_no],
+				dev_ctx->interrupt_reason[instance_no]);
+			ret = -ETIME;
+			break;
+		}
+		if (signal_pending(current)) {
+			ret = -ERESTARTSYS;
+			dev_err(jdev->jdev, "instance no: %d ERESTARTSYS\n", instance_no);
+			break;
+		}
+
+		JLOG(jdev->jdev, "INST(%d) s_interrupt_flag(%d), reason(0x%08x)\n",
+		     instance_no, jdev->s_interrupt_flag[instance_no],
+		     dev_ctx->interrupt_reason[instance_no]);
+
+		spin_lock(&jdev->s_jpu_lock);
+		info.intr_reason = dev_ctx->interrupt_reason[instance_no];
+		jdev->s_interrupt_flag[instance_no] = 0;
+		dev_ctx->interrupt_reason[instance_no] = 0;
+		spin_unlock(&jdev->s_jpu_lock);
+
+		for (i = 0; i < TBU_INSTANCES_NUM; i++) {
+			pInfo = buf_inf[i];
+			dmabuf = pInfo.dmabuf;
+			attach = pInfo.attach;
+			sg_table = pInfo.sgtable;
+
+			if (dmabuf && attach && sg_table) {
+				dma_buf_unmap_attachment(attach, sg_table, DMA_BIDIRECTIONAL);
+				dma_buf_detach(dmabuf, attach);
+				dma_buf_put(dmabuf);
+			}
+		}
+		if (jdev->is_hw_enable) {
+			jpu_disable_jpu_mmu_hw(jdev);
+		}
+		ret = copy_to_user((void __user *)arg, &info, sizeof(jpudrv_intr_info_t));
+		if (ret) {
+			return -EFAULT;
+		}
+#if defined (CONFIG_PM) && defined (DDR_QOS_ENABLE)
+		//freq_qos_update_request(jdev->ddr_qos_rreq, PM_QOS_CPUIDLE_BLOCK_DEFAULT_VALUE);
+		//freq_qos_update_request(jdev->ddr_qos_wreq, PM_QOS_CPUIDLE_BLOCK_DEFAULT_VALUE);
+#endif
+		break;
+	case JDI_IOCTL_SET_CLOCK_GATE:;
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+		ret = down_interruptible(&jdev->s_jpu_sem);
+		if (ret) {
+			return -EAGAIN;
+		}
+
+		if (get_user(clkgate, (u32 __user *) arg)) {
+			up(&jdev->s_jpu_sem);
+			return -EFAULT;
+		}
+
+		if (clkgate) {
+			jpu_clk_enable(jdev);
+		} else {
+			jpu_clk_disable(jdev);
+		}
+
+		up(&jdev->s_jpu_sem);
+#endif
+		break;
+	case JDI_IOCTL_GET_INSTANCE_POOL:
+		ret = down_interruptible(&jdev->s_jpu_sem);
+		if (ret) {
+			return -EAGAIN;
+		}
+
+		if (jdev->s_instance_pool.base) {
+			ret = copy_to_user((void __user *)arg, &jdev->s_instance_pool,
+					   sizeof(jpudrv_buffer_t));
+		} else {
+			ret = copy_from_user(&jdev->s_instance_pool,
+					     (jpudrv_buffer_t *) arg, sizeof(jpudrv_buffer_t));
+			if (!ret) {
+				jdev->s_instance_pool.size = PAGE_ALIGN(jdev->s_instance_pool.size);
+				jdev->s_instance_pool.base =
+				    (unsigned long)vmalloc(jdev->s_instance_pool.size);
+				jdev->s_instance_pool.phys_addr = jdev->s_instance_pool.base;
+
+				if (jdev->s_instance_pool.base != 0) {
+					memset((void *)jdev->s_instance_pool.base, 0x0, jdev->s_instance_pool.size);	/*clearing memory */
+					ret = copy_to_user((void __user *)arg,
+							   &jdev->s_instance_pool, sizeof(jpudrv_buffer_t));
+					if (ret == 0) {
+						/* success to get memory for instance pool */
+						up(&jdev->s_jpu_sem);
+						break;
+					}
+				}
+				ret = -EFAULT;
+			}
+
+		}
+
+		up(&jdev->s_jpu_sem);
+
+		JLOG(jdev->jdev,
+		     "JDI_IOCTL_GET_INSTANCE_POOL: %s base: %lx, size: %d\n",
+		     (ret == 0 ? "OK" : "NG"), jdev->s_instance_pool.base,
+		     jdev->s_instance_pool.size);
+
+		break;
+	case JDI_IOCTL_OPEN_INSTANCE:
+		if (copy_from_user(&inst_info, (jpudrv_inst_info_t *) arg, sizeof(jpudrv_inst_info_t)))
+			return -EFAULT;
+
+		spin_lock(&jdev->s_jpu_lock);
+		jdev->s_jpu_open_ref_count++;	/* flag just for that jpu is in opened or closed */
+		inst_info.inst_open_count = jdev->s_jpu_open_ref_count;
+		spin_unlock(&jdev->s_jpu_lock);
+
+		if (copy_to_user((void __user *)arg, &inst_info, sizeof(jpudrv_inst_info_t))) {
+			return -EFAULT;
+		}
+
+		JLOG(jdev->jdev,
+		     "JDI_IOCTL_OPEN_INSTANCE inst_idx=%d, s_jpu_open_ref_count=%d, inst_open_count=%d\n",
+		     (int)inst_info.inst_idx, jdev->s_jpu_open_ref_count, inst_info.inst_open_count);
+
+		break;
+	case JDI_IOCTL_CLOSE_INSTANCE:
+		if (copy_from_user(&inst_info, (jpudrv_inst_info_t *) arg, sizeof(jpudrv_inst_info_t)))
+			return -EFAULT;
+
+		spin_lock(&jdev->s_jpu_lock);
+		jdev->s_jpu_open_ref_count--;	/* flag just for that jpu is in opened or closed */
+		inst_info.inst_open_count = jdev->s_jpu_open_ref_count;
+		spin_unlock(&jdev->s_jpu_lock);
+
+		if (copy_to_user((void __user *)arg, &inst_info, sizeof(jpudrv_inst_info_t)))
+			return -EFAULT;
+
+		JLOG(jdev->jdev,
+		     "JDI_IOCTL_CLOSE_INSTANCE inst_idx=%d, s_jpu_open_ref_count=%d, inst_open_count=%d\n",
+		     (int)inst_info.inst_idx, jdev->s_jpu_open_ref_count, inst_info.inst_open_count);
+
+		break;
+	case JDI_IOCTL_GET_INSTANCE_NUM:
+		ret = copy_from_user(&inst_info, (jpudrv_inst_info_t *) arg, sizeof(jpudrv_inst_info_t));
+		if (ret != 0)
+			break;
+
+		spin_lock(&jdev->s_jpu_lock);
+		inst_info.inst_open_count = jdev->s_jpu_open_ref_count;
+		spin_unlock(&jdev->s_jpu_lock);
+
+		ret = copy_to_user((void __user *)arg, &inst_info, sizeof(jpudrv_inst_info_t));
+
+		JLOG(jdev->jdev,
+		     "JDI_IOCTL_GET_INSTANCE_NUM inst_idx=%d, open_count=%d\n",
+		     (int)inst_info.inst_idx, inst_info.inst_open_count);
+		break;
+	case JDI_IOCTL_RESET:
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+
+		ret = down_interruptible(&jdev->s_jpu_sem);
+		if (ret) {
+			return -EAGAIN;
+		}
+
+		jpu_hw_reset(jdev);
+
+		up(&jdev->s_jpu_sem);
+#endif
+		break;
+	case JDI_IOCTL_GET_REGISTER_INFO:
+		ret = copy_to_user((void __user *)arg, &jdev->s_jpu_register, sizeof(jpudrv_buffer_t));
+		if (ret != 0) {
+			ret = -EFAULT;
+		}
+		JLOG(jdev->jdev, "JDI_IOCTL_GET_REGISTER_INFO s_jpu_register.phys_addr=0x%lx, s_jpu_register.virt_addr=0x%lx, s_jpu_register.size=%d\n",
+				 jdev->s_jpu_register.phys_addr, jdev->s_jpu_register.virt_addr, jdev->s_jpu_register.size);
+		break;
+	case JDI_IOCTL_CFG_MMU:
+		//JLOG(jdev->jdev, "JDI_IOCTL_CFG_MMU \n");
+		ret = copy_from_user(&cfg, (JPU_DMA_CFG *) arg, sizeof(JPU_DMA_CFG));
+		if (ret != 0) {
+			ret = -EFAULT;
+		}
+		//JLOG(jdev->jdev, "JDI_IOCTL_CFG_MMU input fd:%d output:%d\n",cfg.intput_buf_fd,cfg.output_buf_fd);
+		buf_inf[0].tbu_id = TBU_INPUT;
+		buf_inf[1].tbu_id = TBU_OUTPUT;
+		cfg.intput_virt_addr =
+		    get_addr_from_fd(jdev, cfg.intput_buf_fd, &buf_inf[0], cfg.data_size, cfg.append_buf_size);
+		cfg.output_virt_addr =
+		    get_addr_from_fd(jdev, cfg.output_buf_fd, &buf_inf[1], cfg.data_size, cfg.append_buf_size);
+		ret = copy_to_user((void __user *)arg, &cfg, sizeof(JPU_DMA_CFG));
+		if (ret != 0) {
+			ret = -EFAULT;
+		}
+		jpu_writel(jdev, JPU_MMU_TRI, 0x01);
+#if defined (CONFIG_PM) && defined (DDR_QOS_ENABLE)
+		//_update_request(jdev->ddr_qos_rreq,160000);
+		//freq_qos_update_request(jdev->ddr_qos_wreq,8000);
+#endif
+		JLOG(jdev->jdev, "JDI_IOCTL_CFG_MMU DONE!\n");
+		break;
+	default:
+		dev_err(jdev->jdev, "No such IOCTL, cmd is %d\n", cmd);
+		break;
+	}
+
+	return ret;
+}
+
+static int jpu_fasync(int fd, struct file *filp, int mode)
+{
+	struct jpu_device *jdev = filp->private_data;
+
+	return fasync_helper(fd, filp, mode, &jdev->s_jpu_drv_context.async_queue);
+}
+
+static int jpu_release(struct inode *inode, struct file *filp)
+{
+	struct jpu_device *jdev = filp->private_data;
+	int ret = 0;
+	u32 open_count;
+
+	ret = down_interruptible(&jdev->s_jpu_sem);
+	if (ret) {
+		return -EAGAIN;
+	}
+
+	/* found and free the not handled buffer by user applications */
+	jpu_free_buffers(filp);
+
+	/* found and free the not closed instance by user applications */
+	jpu_free_instances(filp);
+	JLOG(jdev->jdev, "open_count: %d\n", jdev->s_jpu_drv_context.open_count);
+
+	spin_lock(&jdev->s_jpu_lock);
+	jdev->s_jpu_drv_context.open_count--;
+	open_count = jdev->s_jpu_drv_context.open_count;
+	spin_unlock(&jdev->s_jpu_lock);
+
+	if (open_count == 0) {
+		if (jdev->s_instance_pool.base) {
+			JLOG(jdev->jdev, "free instance pool\n");
+			vfree((const void *)jdev->s_instance_pool.base);
+			jdev->s_instance_pool.base = 0;
+		}
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+		jpu_clk_disable(jdev);
+		pm_runtime_put_sync(jdev->jdev);
+
+#endif
+	}
+
+	up(&jdev->s_jpu_sem);
+
+	JLOG(jdev->jdev, "released\n");
+
+	return 0;
+}
+
+static int jpu_map_to_register(struct file *fp, struct vm_area_struct *vm)
+{
+	struct jpu_device *jdev = fp->private_data;
+	unsigned long pfn;
+
+	vm->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
+	vm->vm_page_prot = pgprot_noncached(vm->vm_page_prot);
+	pfn = jdev->s_jpu_register.phys_addr >> PAGE_SHIFT;
+
+	return remap_pfn_range(vm, vm->vm_start, pfn, vm->vm_end - vm->vm_start,
+			       vm->vm_page_prot) ? -EAGAIN : 0;
+}
+
+static int jpu_map_to_physical_memory(struct file *fp, struct vm_area_struct *vm)
+{
+	vm->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
+	vm->vm_page_prot = pgprot_noncached(vm->vm_page_prot);
+
+	return remap_pfn_range(vm, vm->vm_start, vm->vm_pgoff,
+			       vm->vm_end - vm->vm_start, vm->vm_page_prot) ? -EAGAIN : 0;
+}
+
+static int jpu_map_to_instance_pool_memory(struct file *fp, struct vm_area_struct *vm)
+{
+	struct jpu_device *jdev = fp->private_data;
+	int ret;
+	long length = vm->vm_end - vm->vm_start;
+	unsigned long start = vm->vm_start;
+	char *vmalloc_area_ptr = (char *)jdev->s_instance_pool.base;
+	unsigned long pfn;
+
+	vm->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;
+
+	/* loop over all pages, map it page individually */
+	while (length > 0) {
+		pfn = vmalloc_to_pfn(vmalloc_area_ptr);
+		if ((ret = remap_pfn_range(vm, start, pfn, PAGE_SIZE, PAGE_SHARED)) < 0) {
+			return ret;
+		}
+		start += PAGE_SIZE;
+		vmalloc_area_ptr += PAGE_SIZE;
+		length -= PAGE_SIZE;
+	}
+
+	return 0;
+}
+
+static int jpu_mmap(struct file *fp, struct vm_area_struct *vm)
+{
+	struct jpu_device *jdev = fp->private_data;
+
+	if (vm->vm_pgoff == 0)
+		return jpu_map_to_instance_pool_memory(fp, vm);
+
+	if (vm->vm_pgoff == (jdev->s_jpu_register.phys_addr >> PAGE_SHIFT))
+		return jpu_map_to_register(fp, vm);
+
+	return jpu_map_to_physical_memory(fp, vm);
+}
+
+struct file_operations jpu_fops = {
+	.owner = THIS_MODULE,
+	.open = jpu_open,
+	.read = jpu_read,
+	.write = jpu_write,
+	.unlocked_ioctl = jpu_ioctl,
+	.release = jpu_release,
+	.fasync = jpu_fasync,
+	.mmap = jpu_mmap,
+};
+
+static ssize_t cclk_max_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%u\n", jdev->cclk_max_frequency);
+}
+
+static ssize_t cclk_min_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%u\n", jdev->cclk_min_frequency);
+}
+
+static ssize_t cclk_cur_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%u\n", jdev->cclk_cur_frequency);
+}
+
+static ssize_t cclk_cur_frequency_store(struct device *dev,
+					struct device_attribute *attr, const char *buf,
+					size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+	unsigned long cclk_cur_frequency = 0;
+	int ret;
+
+	ret = kstrtoul(buf, 0, &cclk_cur_frequency);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (cclk_cur_frequency < jdev->cclk_min_frequency
+	    || cclk_cur_frequency > jdev->cclk_max_frequency) {
+		return -EINVAL;
+	}
+
+	jdev->cclk_cur_frequency = cclk_cur_frequency;
+
+	return count;
+}
+
+static DEVICE_ATTR_RO(cclk_max_frequency);
+static DEVICE_ATTR_RO(cclk_min_frequency);
+static DEVICE_ATTR_RW(cclk_cur_frequency);
+
+static struct attribute *cclk_frequency_attrs[] = {
+	&dev_attr_cclk_max_frequency.attr,
+	&dev_attr_cclk_min_frequency.attr,
+	&dev_attr_cclk_cur_frequency.attr,
+	NULL,
+};
+
+static const struct attribute_group cclk_frequency_group = {
+	.name = "cclk",
+	.attrs = cclk_frequency_attrs,
+};
+
+static ssize_t aclk_max_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%llu\n", jdev->aclk_max_frequency);
+}
+
+static ssize_t aclk_min_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%u\n", jdev->aclk_min_frequency);
+}
+
+static ssize_t aclk_cur_frequency_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	return sprintf(buf, "%u\n", jdev->aclk_cur_frequency);
+}
+
+static ssize_t aclk_cur_frequency_store(struct device *dev,
+					struct device_attribute *attr, const char *buf,
+					size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+	unsigned long aclk_cur_frequency = 0;
+	int ret;
+
+	ret = kstrtoul(buf, 0, &aclk_cur_frequency);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (aclk_cur_frequency < jdev->aclk_min_frequency
+	    || aclk_cur_frequency > jdev->aclk_max_frequency) {
+		return -EINVAL;
+	}
+
+	jdev->aclk_cur_frequency = aclk_cur_frequency;
+
+	return count;
+}
+
+static DEVICE_ATTR_RO(aclk_max_frequency);
+static DEVICE_ATTR_RO(aclk_min_frequency);
+static DEVICE_ATTR_RW(aclk_cur_frequency);
+
+static struct attribute *aclk_frequency_attrs[] = {
+	&dev_attr_aclk_max_frequency.attr,
+	&dev_attr_aclk_min_frequency.attr,
+	&dev_attr_aclk_cur_frequency.attr,
+	NULL,
+};
+
+static const struct attribute_group aclk_frequency_group = {
+	.name = "aclk",
+	.attrs = aclk_frequency_attrs
+};
+
+static const struct attribute_group *jpu_frequency_group[] = {
+	&cclk_frequency_group,
+	&aclk_frequency_group,
+	NULL,
+};
+
+static const struct of_device_id jpu_dt_match[] = {
+	{
+	 .compatible = "chip-media, jpu",
+	  },
+	{ }
+};
+
+static u64 jpu_dmamask = 0xffffffffffUL;
+
+static int jpu_probe(struct platform_device *pdev)
+{
+	struct jpu_device *jdev;
+	struct resource *res;
+	const struct of_device_id *of_id;
+	uint32_t device_id = 0;
+	char cdev_name[32] = { 0 };
+	int err, i;
+	struct cpumask mask = { CPU_BITS_NONE };
+	int cpuid = 0;
+	void *va_temp;
+	dma_addr_t pa_temp;
+	jdev = devm_kzalloc(&pdev->dev, sizeof(*jdev), GFP_KERNEL);
+	if (!jdev) {
+		return -ENOMEM;
+	}
+
+	jdev->jdev = &pdev->dev;
+	jdev->jdev->dma_mask = &jpu_dmamask;
+	jdev->jdev->coherent_dma_mask = 0xffffffffffull;
+	platform_set_drvdata(pdev, jdev);
+	INIT_LIST_HEAD(&jdev->s_jbp_head);
+	INIT_LIST_HEAD(&jdev->s_inst_list_head);
+	sema_init(&jdev->s_jpu_sem, 1);
+	spin_lock_init(&jdev->s_jpu_lock);
+	for (i = 0; i < MAX_NUM_INSTANCE; i++) {
+		init_waitqueue_head(&jdev->s_interrupt_wait_q[i]);
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (IS_ERR_OR_NULL(res)) {
+		dev_err(jdev->jdev, "No I/O registers defined");
+		return -ENXIO;
+	}
+
+	jdev->reg = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(jdev->reg)) {
+		dev_err(jdev->jdev, "Failed to map JPU registers.\n");
+		return PTR_ERR(jdev->reg);
+	}
+
+	jdev->s_jpu_register.phys_addr = res->start;
+	jdev->s_jpu_register.virt_addr = (unsigned long)jdev->reg;
+	jdev->s_jpu_register.size = resource_size(res);
+
+	jdev->s_jpu_irq = platform_get_irq(pdev, 0);
+	if (jdev->s_jpu_irq < 0) {
+		dev_err(jdev->jdev, "No irq defined\n");
+		return -ENXIO;
+	}
+	err = of_property_read_u32(pdev->dev.of_node, "page-size", &jdev->page_size);
+	if (err == 0)
+		jdev->page_size *= SZ_1K;
+	else
+		jdev->page_size = SZ_4K;
+
+	jdev->is_hw_enable = false;
+	va_temp = dma_alloc_coherent(jdev->jdev, MAX_SIZE_PER_TTB * TBU_INSTANCES_NUM,
+				     &pa_temp, GFP_KERNEL | GFP_DMA);
+	if (!va_temp) {
+		dev_err(jdev->jdev, "No memory for %d tbu_ins!\n", TBU_INSTANCES_NUM);
+		goto err0;
+	}
+	for (i = 0; i < TBU_INSTANCES_NUM; i++) {
+		struct tbu_instance *tbu = &jdev->tbu_ins[i];
+		tbu->ttb_va = va_temp + i * MAX_SIZE_PER_TTB;
+		tbu->ttb_pa = pa_temp + i * MAX_SIZE_PER_TTB;
+		tbu->ins_id = i;
+	}
+	spin_lock_init(&jdev->tbu_ins_bitmap_lock);
+
+	jdev->va_base = BASE_VIRTUAL_ADDRESS;
+	jdev->va_end = BASE_VIRTUAL_ADDRESS + TBU_NUM * VA_STEP_PER_TBU;
+	jdev->time_out_cycs = DEFAULT_TIMEOUT_CYCS;
+
+	spin_lock_init(&jdev->hw_access_lock);
+	err = devm_request_irq(&pdev->dev, jdev->s_jpu_irq, jpu_irq_handler, 0, "JPU", jdev);
+	if (err) {
+		dev_err(jdev->jdev, "irq not be registered\n");
+		return err;
+	}
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+
+	jdev->aclk = devm_clk_get(&pdev->dev, "aclk");
+	if (IS_ERR_OR_NULL(jdev->aclk)) {
+		dev_err(jdev->jdev, "not found axi clk\n");
+		return PTR_ERR(jdev->aclk);
+	}
+	atomic_set(&jdev->aclk_enable_count, 0);
+	jdev->cclk = devm_clk_get(&pdev->dev, "cclk");
+	if (IS_ERR_OR_NULL(jdev->cclk)) {
+		dev_err(jdev->jdev, "not found core clock\n");
+		return PTR_ERR(jdev->cclk);
+	}
+	atomic_set(&jdev->cclk_enable_count, 0);
+	if (of_property_read_u32(pdev->dev.of_node, "jpu,cclk-max-frequency", &jdev->cclk_max_frequency)) {
+		dev_err(jdev->jdev, "not read cclk max frequency.\n");
+		return -ENXIO;
+	}
+
+	if (of_property_read_u32(pdev->dev.of_node, "jpu,cclk-min-frequency", &jdev->cclk_min_frequency)) {
+		dev_err(jdev->jdev, "not read cclk min frequency.\n");
+		return -ENXIO;
+	}
+
+	if (of_property_read_u32(pdev->dev.of_node, "jpu,cclk-default-frequency", &jdev->cclk_default_frequency)) {
+		dev_err(jdev->jdev, "not read cclk default frequency.\n");
+		return -ENXIO;
+	} else {
+		jdev->cclk_cur_frequency = jdev->cclk_default_frequency;
+	}
+
+	jdev->iclk = devm_clk_get(&pdev->dev, "iclk");
+	if (IS_ERR_OR_NULL(jdev->iclk)) {
+		dev_err(jdev->jdev, "not found core clock\n");
+		return PTR_ERR(jdev->iclk);
+	}
+	atomic_set(&jdev->iclk_enable_count, 0);
+#endif
+	jdev->jpg_reset = devm_reset_control_get_optional_shared(&pdev->dev, "jpg_reset");
+	if (IS_ERR_OR_NULL(jdev->jpg_reset)) {
+		dev_err(jdev->jdev, "not found core jpg_reset\n");
+		return PTR_ERR(jdev->jpg_reset);
+	}
+	atomic_set(&jdev->jpg_reset_enable_count, 0);
+	jdev->lcd_mclk_reset = devm_reset_control_get_optional_shared(&pdev->dev, "lcd_mclk_reset");
+	if (IS_ERR_OR_NULL(jdev->lcd_mclk_reset)) {
+		dev_err(jdev->jdev, "not found core lcd_mclk_reset\n");
+		return PTR_ERR(jdev->lcd_mclk_reset);
+	}
+	atomic_set(&jdev->lcd_mclk_reset_enable_count, 0);
+	jdev->isp_ci_reset = devm_reset_control_get_optional_shared(&pdev->dev, "isp_ci_reset");
+	if (IS_ERR_OR_NULL(jdev->isp_ci_reset)) {
+		dev_err(jdev->jdev, "not found core isp_ci_reset\n");
+		return PTR_ERR(jdev->isp_ci_reset);
+	}
+	atomic_set(&jdev->isp_ci_reset_enable_count, 0);
+	jdev->freset = devm_reset_control_get_optional_shared(&pdev->dev, "freset");
+	if (IS_ERR_OR_NULL(jdev->freset)) {
+		dev_err(jdev->jdev, "not found core freset\n");
+		return PTR_ERR(jdev->freset);
+	}
+	atomic_set(&jdev->freset_enable_count, 0);
+	jdev->sreset = devm_reset_control_get_optional_shared(&pdev->dev, "sreset");
+	if (IS_ERR_OR_NULL(jdev->sreset)) {
+		dev_err(jdev->jdev, "not found core sreset\n");
+		return PTR_ERR(jdev->sreset);
+	}
+	atomic_set(&jdev->sreset_enable_count, 0);
+
+	of_id = of_match_device(jpu_dt_match, &pdev->dev);
+	if (!of_id) {
+		dev_err(jdev->jdev, "No matching device to of_node: %p.\n", pdev->dev.of_node);
+		return -EINVAL;
+	}
+
+	if (of_property_read_u32(pdev->dev.of_node, "jpu,chip-id", &device_id)) {
+		dev_err(jdev->jdev, "not found device id defined.\n");
+		return -ENXIO;
+	}
+
+	snprintf(cdev_name, sizeof(cdev_name), "%s%d", "jpu", device_id);
+	JLOG(jdev->jdev, "cdev name %s\n", cdev_name);
+	if ((alloc_chrdev_region(&jdev->s_jpu_major, 0, 1, cdev_name)) < 0) {
+		dev_err(jdev->jdev, "could not allocate major number\n");
+		return -EBUSY;
+	}
+
+	/* initialize the device structure and register the device with the kernel */
+	cdev_init(&jdev->s_jpu_cdev, &jpu_fops);
+	jdev->s_jpu_cdev.owner = THIS_MODULE;
+
+	/* Register char dev with the kernel */
+	if ((cdev_add(&jdev->s_jpu_cdev, jdev->s_jpu_major, 1)) < 0) {
+		dev_err(jdev->jdev, "could not allocate chrdev\n");
+		return -EBUSY;
+	}
+
+	JLOG(jdev->jdev, "cdev major %d, minor %d\n", MAJOR(jdev->s_jpu_major),
+	     MINOR(jdev->s_jpu_major));
+
+	/* Create class for device driver. */
+	jdev->jpu_class = class_create(THIS_MODULE, cdev_name);
+
+	/* Create a device node. */
+	jdev->jpu_device = device_create(jdev->jpu_class, NULL, jdev->s_jpu_major, NULL, cdev_name);
+
+	err = sysfs_create_groups(&pdev->dev.kobj, jpu_frequency_group);
+	if (err < 0) {
+		return err;
+	}
+	pm_runtime_set_active(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+#if defined (CONFIG_PM) && defined (DDR_QOS_ENABLE)
+#if 0
+	jdev->ddr_qos_cons = ddr_get_freq_constraints();
+	jdev->ddr_qos_rreq = &jpu_ddrfreq_qos_rreq_sum;
+	jdev->ddr_qos_wreq = &jpu_ddrfreq_qos_wreq_sum;
+	freq_qos_add_request(jdev->ddr_qos_cons, jdev->ddr_qos_rreq, FREQ_QOS_RSUM,
+			     PM_QOS_CPUIDLE_BLOCK_DEFAULT_VALUE);
+	freq_qos_add_request(jdev->ddr_qos_cons, jdev->ddr_qos_wreq, FREQ_QOS_WSUM,
+			     PM_QOS_CPUIDLE_BLOCK_DEFAULT_VALUE);
+#endif
+#endif
+	cpuid = 0;
+	cpumask_set_cpu(cpuid, &mask);
+	irq_set_affinity(jdev->s_jpu_irq, &mask);
+	dev_notice(jdev->jdev, "driver probe successfully\n");
+	return 0;
+err0:
+	return -1;
+}
+
+static int jpu_remove(struct platform_device *pdev)
+{
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+
+	if (jdev->s_instance_pool.base) {
+		vfree((const void *)jdev->s_instance_pool.base);
+		jdev->s_instance_pool.base = 0;
+	}
+
+	if (jdev->jpu_device) {
+		device_destroy(jdev->jpu_class, jdev->s_jpu_major);
+	}
+
+	if (jdev->jpu_class) {
+		class_destroy(jdev->jpu_class);
+	}
+
+	if (jdev->s_jpu_major) {
+		cdev_del(&jdev->s_jpu_cdev);
+		unregister_chrdev_region(jdev->s_jpu_major, 1);
+		jdev->s_jpu_major = 0;
+	}
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+	jpu_clk_disable(jdev);
+	pm_runtime_disable(&pdev->dev);
+#endif
+	sysfs_remove_groups(&pdev->dev.kobj, jpu_frequency_group);
+
+	dev_notice(jdev->jdev, "driver removed\n");
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int jpu_suspend(struct platform_device *pdev, pm_message_t state)
+{
+#ifndef CONFIG_SOC_SPACEMIT_K1_FPGA
+	struct jpu_device *jdev = platform_get_drvdata(pdev);
+	jpu_clk_disable(jdev);
+#endif
+
+	return 0;
+}
+
+static int jpu_resume(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static int jpu_runtime_suspend(struct device *dev)
+{
+	return 0;
+}
+
+static int jpu_runtime_resume(struct device *dev)
+{
+    return 0;
+}
+
+static const struct dev_pm_ops jpu_pm_ops = {
+	.runtime_suspend = jpu_runtime_suspend,
+	.runtime_resume  = jpu_runtime_resume,
+};
+#else
+#define jpu_suspend NULL
+#define jpu_resume NULL
+#define jpu_runtime_suspend NULL
+#define jpu_runtime_resume NULL
+#endif
+
+static struct platform_driver jpu_driver = {
+	.driver = {
+			.name = "jpu",
+			.of_match_table = jpu_dt_match,
+#ifdef CONFIG_PM
+			.pm             = &jpu_pm_ops
+#endif /* CONFIG_PM */
+		    },
+	.probe = jpu_probe,
+	.remove = jpu_remove,
+	.suspend = jpu_suspend,
+	.resume = jpu_resume,
+};
+
+static int __init jpu_init(void)
+{
+	jpu_exp_init();
+	return platform_driver_register(&jpu_driver);
+}
+
+static void __exit jpu_exit(void)
+{
+	jpu_exp_exit();
+	platform_driver_unregister(&jpu_driver);
+}
+
+MODULE_AUTHOR("SPACEMIT Limited, Inc.");
+MODULE_DESCRIPTION("JPU linux driver");
+MODULE_LICENSE("Proprietary");
+
+module_init(jpu_init);
+module_exit(jpu_exit);
diff --git a/drivers/soc/spacemit/jpu/jpu.h b/drivers/soc/spacemit/jpu/jpu.h
new file mode 100644
index 000000000000..09faa5cba203
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jpu.h
@@ -0,0 +1,91 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef __JPU_DRV_H__
+#define __JPU_DRV_H__
+
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/dma-buf.h>
+#include <linux/highmem.h>
+#include <linux/dma-mapping.h>
+#include <linux/io.h>
+#include <linux/iommu.h>
+
+#define JDI_IOCTL_MAGIC  'J'
+
+#define JDI_IOCTL_ALLOCATE_PHYSICAL_MEMORY          _IO(JDI_IOCTL_MAGIC, 0)
+#define JDI_IOCTL_FREE_PHYSICALMEMORY               _IO(JDI_IOCTL_MAGIC, 1)
+#define JDI_IOCTL_WAIT_INTERRUPT                    _IO(JDI_IOCTL_MAGIC, 2)
+#define JDI_IOCTL_SET_CLOCK_GATE                    _IO(JDI_IOCTL_MAGIC, 3)
+#define JDI_IOCTL_RESET                             _IO(JDI_IOCTL_MAGIC, 4)
+#define JDI_IOCTL_GET_INSTANCE_POOL                 _IO(JDI_IOCTL_MAGIC, 5)
+#define JDI_IOCTL_GET_RESERVED_VIDEO_MEMORY_INFO    _IO(JDI_IOCTL_MAGIC, 6)
+#define JDI_IOCTL_GET_REGISTER_INFO                 _IO(JDI_IOCTL_MAGIC, 7)
+#define JDI_IOCTL_OPEN_INSTANCE                     _IO(JDI_IOCTL_MAGIC, 8)
+#define JDI_IOCTL_CLOSE_INSTANCE                    _IO(JDI_IOCTL_MAGIC, 9)
+#define JDI_IOCTL_GET_INSTANCE_NUM                  _IO(JDI_IOCTL_MAGIC, 10)
+#define JDI_IOCTL_CFG_MMU                     		_IO(JDI_IOCTL_MAGIC, 11)
+#define JDI_IOCTL_RELEASE_MMU                     	_IO(JDI_IOCTL_MAGIC, 12)
+
+enum {
+	INT_JPU_DONE = 0,
+	INT_JPU_ERROR = 1,
+	INT_JPU_BIT_BUF_EMPTY = 2,
+	INT_JPU_BIT_BUF_FULL = 2,
+	INT_JPU_OVERFLOW,
+	INT_JPU_PARTIAL_BUFFER_0,
+	INT_JPU_PARTIAL_BUFFER_1,
+	INT_JPU_PARTIAL_BUFFER_2,
+	INT_JPU_PARTIAL_BUFFER_3,
+	INT_JPU_STOP,
+	INT_JPU_CFG_DONE,
+	INT_JPU_SOF,
+};
+
+typedef struct jpudrv_buffer_t {
+	unsigned int size;
+	unsigned long phys_addr;
+	unsigned long base;	/* kernel logical address in use kernel */
+	unsigned long virt_addr;	/* virtual user space address */
+} jpudrv_buffer_t;
+
+typedef struct jpudrv_inst_info_t {
+	unsigned int inst_idx;
+	int inst_open_count;	/* for output only */
+} jpudrv_inst_info_t;
+
+typedef struct jpudrv_intr_info_t {
+	unsigned int timeout;
+	int intr_reason;
+	unsigned int inst_idx;
+} jpudrv_intr_info_t;
+
+typedef struct jpu_dma_buf_info {
+	struct dma_buf *dmabuf;
+	int buf_fd;
+	struct dma_buf_attachment *attach;
+	struct sg_table *sgtable;
+	int tbu_id;
+	u32 append_buf_size;	//append buffer to workarourd when picture size is not 16 align 
+} jpu_dma_buf_info;
+typedef struct jpu_dma_cfg {
+	int intput_buf_fd;
+	int output_buf_fd;
+	unsigned int intput_virt_addr;
+	unsigned int output_virt_addr;
+	unsigned int data_size;
+	unsigned int append_buf_size;
+} JPU_DMA_CFG;
+struct tbu_instance {
+	int ins_id;
+	u32 *ttb_va;
+	dma_addr_t ttb_pa;
+	u64 ttb_size;
+	u64 va_base;
+	u64 va_end;
+	bool always_preload;
+	bool enable_preload;
+	u32 nsaid;
+	u32 qos;
+	bool secure_enable;
+};
+#endif
diff --git a/drivers/soc/spacemit/jpu/jpu_export.c b/drivers/soc/spacemit/jpu/jpu_export.c
new file mode 100644
index 000000000000..641ee2ae2118
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jpu_export.c
@@ -0,0 +1,302 @@
+// SPDX-License-Identifier: GPL-2.0
+
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/fs.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/miscdevice.h>
+#include <linux/dma-mapping.h>
+#include <linux/genalloc.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/iommu.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/dma-buf.h>
+#include <linux/highmem.h>
+#include <linux/types.h>
+#include <linux/types.h>
+#include "jpu_export.h"
+struct jpu_alloc_dma_buf {
+	__s32 fd;		/* fd */
+	__u32 flags;		/* flags to map with */
+	__u64 size;		/* size */
+};
+struct jpu_data {
+	bool is_continue;
+	int npages;
+	unsigned int size;
+	struct page *pages[];
+};
+
+#define jpu_IOCTL_ALLOC_DMA_BUF \
+	_IOWR('V', 10, struct jpu_alloc_dma_buf)
+
+static struct device *pdev;
+static int jpu_exporter_attach(struct dma_buf *dmabuf, struct dma_buf_attachment *attachment)
+{
+	return 0;
+}
+
+static void jpu_exporter_detach(struct dma_buf *dmabuf, struct dma_buf_attachment *attachment)
+{
+}
+
+static struct sg_table *jpu_exporter_map_dma_buf(struct dma_buf_attachment *attachment,
+						 enum dma_data_direction dir)
+{
+	struct jpu_data *data;
+	struct sg_table *table;
+	struct scatterlist *sg;
+	int i;
+
+	data = attachment->dmabuf->priv;
+	table = kmalloc(sizeof(*table), GFP_KERNEL);
+	if (!table)
+		return ERR_PTR(-ENOMEM);
+
+	if (sg_alloc_table(table, data->npages, GFP_KERNEL)) {
+		kfree(table);
+		return ERR_PTR(-ENOMEM);
+	}
+	sg = table->sgl;
+	for (i = 0; i < data->npages; i++) {
+		sg_set_page(sg, data->pages[i], data->size, 0);
+		sg = sg_next(sg);
+	}
+
+	if (!dma_map_sg(pdev, table->sgl, table->nents, dir)) {
+		sg_free_table(table);
+		kfree(table);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	return table;
+}
+
+static void jpu_exporter_unmap_dma_buf(struct dma_buf_attachment *attachment,
+				       struct sg_table *table, enum dma_data_direction dir)
+{
+	dma_unmap_sg(pdev, table->sgl, table->nents, dir);
+	sg_free_table(table);
+	kfree(table);
+}
+
+static void jpu_exporter_release(struct dma_buf *dma_buf)
+{
+	struct jpu_data *data = dma_buf->priv;
+	int i;
+
+	pr_info("dmabuf release data:%px\n", data);
+
+	for (i = 0; i < data->npages; i++)
+		put_page(data->pages[i]);
+
+	kfree(data);
+}
+
+static int jpu_exporter_mmap(struct dma_buf *dma_buf, struct vm_area_struct *vma)
+{
+	struct jpu_data *data = dma_buf->priv;
+	unsigned long vm_start = vma->vm_start;
+	unsigned long size = vma->vm_end - vma->vm_start;
+	int i = 0, ret;
+	//pr_info("dma mmap vm start:0x%llx,size:0x%llx\n", vm_start, size);
+	if (data->is_continue) {
+		ret = remap_pfn_range(vma, vm_start, page_to_pfn(data->pages[i]),
+				      size, vma->vm_page_prot);
+	} else {
+		for (i = 0; i < data->npages; i++) {
+			remap_pfn_range(vma, vm_start, page_to_pfn(data->pages[i]),
+					PAGE_SIZE, vma->vm_page_prot);
+			vm_start += PAGE_SIZE;
+		}
+	}
+	return 0;
+}
+
+static int jpu_exporter_begin_cpu_access(struct dma_buf *dmabuf, enum dma_data_direction dir)
+{
+	struct dma_buf_attachment *attachment;
+	struct sg_table *table;
+
+	if (list_empty(&dmabuf->attachments))
+		return 0;
+
+	attachment = list_first_entry(&dmabuf->attachments, struct dma_buf_attachment, node);
+	table = attachment->priv;
+	dma_sync_sg_for_cpu(NULL, table->sgl, table->nents, dir);
+
+	return 0;
+}
+
+static int jpu_exporter_end_cpu_access(struct dma_buf *dmabuf, enum dma_data_direction dir)
+{
+	struct dma_buf_attachment *attachment;
+	struct sg_table *table;
+
+	if (list_empty(&dmabuf->attachments))
+		return 0;
+
+	attachment = list_first_entry(&dmabuf->attachments, struct dma_buf_attachment, node);
+	table = attachment->priv;
+	dma_sync_sg_for_device(NULL, table->sgl, table->nents, dir);
+
+	return 0;
+}
+
+static const struct dma_buf_ops jpu_dmabuf_ops = {
+	.attach = jpu_exporter_attach,
+	.detach = jpu_exporter_detach,
+	.map_dma_buf = jpu_exporter_map_dma_buf,
+	.unmap_dma_buf = jpu_exporter_unmap_dma_buf,
+	.release = jpu_exporter_release,
+	.mmap = jpu_exporter_mmap,
+	.begin_cpu_access = jpu_exporter_begin_cpu_access,
+	.end_cpu_access = jpu_exporter_end_cpu_access,
+};
+
+//#define ALLOC_PAGES
+#ifndef ALLOC_PAGES
+static struct dma_buf *jpu_exp_alloc(struct jpu_alloc_dma_buf *alloc_data)
+{
+	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
+	struct dma_buf *dmabuf;
+	struct jpu_data *data;
+
+	int i, npages, size;
+
+	size = alloc_data->size;
+	npages = PAGE_ALIGN(size) / PAGE_SIZE;
+	if (!npages)
+		return ERR_PTR(-EINVAL);
+
+	data = kmalloc(sizeof(*data) + npages * sizeof(struct page *), GFP_KERNEL);
+	if (!data)
+		return ERR_PTR(-ENOMEM);
+
+	data->is_continue = 0;
+	for (i = 0; i < npages; i++) {
+		data->pages[i] = alloc_page(GFP_KERNEL);
+		if (!data->pages[i])
+			goto err;
+	}
+	data->npages = npages;
+	data->size = PAGE_SIZE;
+	pr_info("dmabuf alloc data:%px, npages:%d, size:0x%x\n", data, npages, size);
+
+	exp_info.ops = &jpu_dmabuf_ops;
+	exp_info.size = npages * PAGE_SIZE;
+	exp_info.flags = O_CLOEXEC | O_RDWR;
+	exp_info.priv = data;
+
+	dmabuf = dma_buf_export(&exp_info);
+	if (IS_ERR(dmabuf))
+		goto err;
+
+	return dmabuf;
+
+err:
+	while (i--)
+		put_page(data->pages[i]);
+	kfree(data);
+	return ERR_PTR(-ENOMEM);
+}
+#else
+static struct dma_buf *jpu_exp_alloc(struct jpu_alloc_dma_buf *alloc_data)
+{
+	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
+	struct dma_buf *dmabuf;
+	struct jpu_data *data;
+	int npages, size, order;
+
+	size = alloc_data->size;
+	npages = PAGE_ALIGN(size) / PAGE_SIZE;
+	order = get_order(size);
+	if (!npages)
+		return ERR_PTR(-EINVAL);
+
+	npages = 1 << order;
+	data = kmalloc(sizeof(*data) + sizeof(struct page *), GFP_KERNEL);
+	if (!data)
+		return ERR_PTR(-ENOMEM);
+	data->is_continue = 1;
+	data->pages[0] = alloc_pages(GFP_KERNEL, order);
+	data->npages = 1;
+	data->size = npages * PAGE_SIZE;
+	pr_info("dmabuf alloc data:%px, real num:%d, order:%d, size:0x%x\n", data,
+		npages, order, size);
+
+	exp_info.ops = &jpu_dmabuf_ops;
+	exp_info.size = npages * PAGE_SIZE;
+	exp_info.flags = O_CLOEXEC | O_RDWR;
+	exp_info.priv = data;
+
+	dmabuf = dma_buf_export(&exp_info);
+	if (IS_ERR(dmabuf))
+		goto err;
+
+	return dmabuf;
+
+err:
+	put_page(data->pages[0]);
+	kfree(data);
+	return ERR_PTR(-ENOMEM);
+}
+#endif
+
+static long jpu_exp_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	struct dma_buf *dmabuf = NULL;
+	unsigned int fd;
+	struct jpu_alloc_dma_buf alloc_data;
+	switch (cmd) {
+	case jpu_IOCTL_ALLOC_DMA_BUF:
+		if (copy_from_user(&alloc_data, (void __user *)arg, sizeof(alloc_data)))
+			return -EFAULT;
+
+		dmabuf = jpu_exp_alloc(&alloc_data);
+		if (!dmabuf) {
+			pr_err("error: exporter alloc page failed\n");
+			return -ENOMEM;
+		}
+		fd = dma_buf_fd(dmabuf, O_CLOEXEC);
+		pr_info("dmabuf fd:%d\n", fd);
+		alloc_data.fd = fd;
+		if (copy_to_user((void __user *)arg, &alloc_data, sizeof(alloc_data)))
+			return -EFAULT;
+		break;
+	default:
+		break;
+	}
+	return 0;
+}
+
+static struct file_operations jpu_exp_fops = {
+	.owner = THIS_MODULE,
+	.unlocked_ioctl = jpu_exp_ioctl,
+};
+
+static struct miscdevice jpu_exp = {
+	.minor = MISC_DYNAMIC_MINOR,
+	.name = "jpu_exp",
+	.fops = &jpu_exp_fops,
+};
+
+static u64 jpu_exp_dmamask = 0xffffffffffUL;
+
+int jpu_exp_init(void)
+{
+	int ret;
+	ret = misc_register(&jpu_exp);
+	pdev = jpu_exp.this_device;
+	pdev->dma_mask = &jpu_exp_dmamask;
+	pdev->coherent_dma_mask = 0xffffffffffull;
+	return ret;
+}
+
+void jpu_exp_exit(void)
+{
+	misc_deregister(&jpu_exp);
+}
diff --git a/drivers/soc/spacemit/jpu/jpu_export.h b/drivers/soc/spacemit/jpu/jpu_export.h
new file mode 100644
index 000000000000..837d45afcb67
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jpu_export.h
@@ -0,0 +1,7 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef __CNM_JPU_EXP_H__
+#define __CNM_JPU_EXP_H__
+int jpu_exp_init(void);
+void jpu_exp_exit(void);
+#endif /* __CNM_JPU_EXP_H__ */
diff --git a/drivers/soc/spacemit/jpu/jpuconfig.h b/drivers/soc/spacemit/jpu/jpuconfig.h
new file mode 100644
index 000000000000..f81b8dd5af82
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/jpuconfig.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef _JPU_CONFIG_H_
+#define _JPU_CONFIG_H_
+
+#include "config.h"
+
+#define MAX_NUM_JPU_CORE                1
+#define MAX_NUM_INSTANCE                1
+#define MAX_INST_HANDLE_SIZE            48
+
+#define JPU_FRAME_ENDIAN                JDI_LITTLE_ENDIAN
+#define JPU_STREAM_ENDIAN               JDI_LITTLE_ENDIAN
+#define JPU_CHROMA_INTERLEAVE           1	// 0 (chroma separate mode), 1 (cbcr interleave mode), 2 (crcb interleave mode)
+
+#define JPU_STUFFING_BYTE_FF            0	// 0 : ON ("0xFF"), 1 : OFF ("0x00") for stuffing
+
+#define MAX_MJPG_PIC_WIDTH              32768
+#define MAX_MJPG_PIC_HEIGHT             32768
+
+#define MAX_FRAME                       (19*MAX_NUM_INSTANCE)
+
+#define STREAM_FILL_SIZE                0x10000
+#define STREAM_END_SIZE                 0
+
+#define JPU_GBU_SIZE                    256
+
+#define STREAM_BUF_SIZE                 0x200000
+
+#define JPU_CHECK_WRITE_RESPONSE_BVALID_SIGNAL 0
+
+#define JPU_INTERRUPT_TIMEOUT_MS        (5000*4)
+#ifdef CNM_SIM_PLATFORM
+#undef JPU_INTERRUPT_TIMEOUT_MS
+#define JPU_INTERRUPT_TIMEOUT_MS        3600000	// 1 hour for simultation environment
+#endif
+
+#define JPU_INST_CTRL_TIMEOUT_MS        (5000*4)
+#ifdef CNM_SIM_PLATFORM
+#undef JPU_INST_CTRL_TIMEOUT_MS
+#define JPU_INST_CTRL_TIMEOUT_MS        3600000	// 1 hour for simulation environment
+#endif
+#endif /* _JPU_CONFIG_H_ */
diff --git a/drivers/soc/spacemit/jpu/regdefine.h b/drivers/soc/spacemit/jpu/regdefine.h
new file mode 100644
index 000000000000..b36ef2ed8dd6
--- /dev/null
+++ b/drivers/soc/spacemit/jpu/regdefine.h
@@ -0,0 +1,141 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef NPT_REGDEFINE_H_INCLUDED
+#define NPT_REGDEFINE_H_INCLUDED
+//------------------------------------------------------------------------------
+// REGISTER BASE
+//------------------------------------------------------------------------------
+#ifndef NIEUPORT_BASE
+//#define NIEUPORT_BASE (0xB00)
+#define NIEUPORT_BASE (0x0)
+
+#endif
+
+#ifndef MMU_BASE
+#define MMU_BASE (0x500)
+#endif
+
+//===================================================================================
+// NIEUPORT REGISTERS
+//===================================================================================
+#define MJPEG_PIC_START_REG         (NIEUPORT_BASE + 0x0000)
+#define MJPEG_PIC_STATUS_REG        (NIEUPORT_BASE + 0x0004)
+#define MJPEG_PIC_ERRMB_REG         (NIEUPORT_BASE + 0x0008)
+#define MJPEG_PIC_SETMB_REG         (NIEUPORT_BASE + 0x000C)
+
+#define MJPEG_PIC_CTRL_REG          (NIEUPORT_BASE + 0x0010)
+#define MJPEG_PIC_SIZE_REG          (NIEUPORT_BASE + 0x0014)
+#define MJPEG_MCU_INFO_REG          (NIEUPORT_BASE + 0x0018)
+#define MJPEG_ROT_INFO_REG          (NIEUPORT_BASE + 0x001C)
+
+#define MJPEG_SCL_INFO_REG          (NIEUPORT_BASE + 0x0020)
+#define MJPEG_IF_INFO_REG           (NIEUPORT_BASE + 0x0024)
+#define MJPEG_CLP_INFO_REG          (NIEUPORT_BASE + 0x0028)
+#define MJPEG_OP_INFO_REG           (NIEUPORT_BASE + 0x002C)
+
+#define MJPEG_DPB_CONFIG_REG        (NIEUPORT_BASE + 0x0030)
+#define MJPEG_DPB_BASE00_REG        (NIEUPORT_BASE + 0x0034)
+#define MJPEG_DPB_BASE01_REG        (NIEUPORT_BASE + 0x0038)
+#define MJPEG_DPB_BASE02_REG        (NIEUPORT_BASE + 0x003C)
+#define MJPEG_DPB_BASE10_REG        (NIEUPORT_BASE + 0x0040)
+#define MJPEG_DPB_BASE11_REG        (NIEUPORT_BASE + 0x0044)
+#define MJPEG_DPB_BASE12_REG        (NIEUPORT_BASE + 0x0048)
+#define MJPEG_DPB_BASE20_REG        (NIEUPORT_BASE + 0x004C)
+#define MJPEG_DPB_BASE21_REG        (NIEUPORT_BASE + 0x0050)
+#define MJPEG_DPB_BASE22_REG        (NIEUPORT_BASE + 0x0054)
+#define MJPEG_DPB_BASE30_REG        (NIEUPORT_BASE + 0x0058)
+#define MJPEG_DPB_BASE31_REG        (NIEUPORT_BASE + 0x005C)
+#define MJPEG_DPB_BASE32_REG        (NIEUPORT_BASE + 0x0060)
+#define MJPEG_DPB_YSTRIDE_REG       (NIEUPORT_BASE + 0x0064)
+#define MJPEG_DPB_CSTRIDE_REG       (NIEUPORT_BASE + 0x0068)
+#define MJPEG_WRESP_CHECK_REG       (NIEUPORT_BASE + 0x006C)
+
+#define MJPEG_CLP_BASE_REG          (NIEUPORT_BASE + 0x0070)
+#define MJPEG_CLP_SIZE_REG          (NIEUPORT_BASE + 0x0074)
+#define MJPEG_HUFF_CTRL_REG         (NIEUPORT_BASE + 0x0080)
+#define MJPEG_HUFF_ADDR_REG         (NIEUPORT_BASE + 0x0084)
+#define MJPEG_HUFF_DATA_REG         (NIEUPORT_BASE + 0x0088)
+#define MJPEG_QMAT_CTRL_REG         (NIEUPORT_BASE + 0x0090)
+#define MJPEG_QMAT_ADDR_REG         (NIEUPORT_BASE + 0x0094)
+#define MJPEG_QMAT_DATA_REG         (NIEUPORT_BASE + 0x0098)
+#define MJPEG_COEF_CTRL_REG         (NIEUPORT_BASE + 0x00A0)
+#define MJPEG_COEF_ADDR_REG         (NIEUPORT_BASE + 0x00A4)
+#define MJPEG_COEF_DATA_REG         (NIEUPORT_BASE + 0x00A8)
+#define MJPEG_RST_INTVAL_REG        (NIEUPORT_BASE + 0x00B0)
+#define MJPEG_RST_INDEX_REG         (NIEUPORT_BASE + 0x00B4)
+#define MJPEG_RST_COUNT_REG         (NIEUPORT_BASE + 0x00B8)
+#define MJPEG_INTR_MASK_REG         (NIEUPORT_BASE + 0x00C0)
+#define MJPEG_CYCLE_INFO_REG        (NIEUPORT_BASE + 0x00C8)
+#define MJPEG_DPCM_DIFF_Y_REG       (NIEUPORT_BASE + 0x00F0)
+#define MJPEG_DPCM_DIFF_CB_REG      (NIEUPORT_BASE + 0x00F4)
+#define MJPEG_DPCM_DIFF_CR_REG      (NIEUPORT_BASE + 0x00F8)
+
+// GBU
+#define MJPEG_GBU_CTRL_REG          (NIEUPORT_BASE + 0x0100)
+#define MJPEG_GBU_PBIT_BUSY_REG     (NIEUPORT_BASE + 0x0104)
+#define MJPEG_GBU_BT_PTR_REG        (NIEUPORT_BASE + 0x0110)
+#define MJPEG_GBU_WD_PTR_REG        (NIEUPORT_BASE + 0x0114)
+#define MJPEG_GBU_TT_CNT_REG        (NIEUPORT_BASE + 0x0118)
+#define MJPEG_GBU_PBIT_08_REG       (NIEUPORT_BASE + 0x0120)
+#define MJPEG_GBU_PBIT_16_REG       (NIEUPORT_BASE + 0x0124)
+#define MJPEG_GBU_PBIT_24_REG       (NIEUPORT_BASE + 0x0128)
+#define MJPEG_GBU_PBIT_32_REG       (NIEUPORT_BASE + 0x012C)
+#define MJPEG_GBU_BBSR_REG          (NIEUPORT_BASE + 0x0140)
+#define MJPEG_GBU_BBER_REG          (NIEUPORT_BASE + 0x0144)
+#define MJPEG_GBU_BBIR_REG          (NIEUPORT_BASE + 0x0148)
+#define MJPEG_GBU_BBHR_REG          (NIEUPORT_BASE + 0x014C)
+#define MJPEG_GBU_BCNT_REG          (NIEUPORT_BASE + 0x0158)
+#define MJPEG_GBU_FF_RPTR_REG       (NIEUPORT_BASE + 0x0160)
+#define MJPEG_GBU_FF_WPTR_REG       (NIEUPORT_BASE + 0x0164)
+
+// BBC
+#define MJPEG_BBC_END_ADDR_REG      (NIEUPORT_BASE + 0x0208)
+#define MJPEG_BBC_WR_PTR_REG        (NIEUPORT_BASE + 0x020C)
+#define MJPEG_BBC_RD_PTR_REG        (NIEUPORT_BASE + 0x0210)
+#define MJPEG_BBC_EXT_ADDR_REG      (NIEUPORT_BASE + 0x0214)
+#define MJPEG_BBC_INT_ADDR_REG      (NIEUPORT_BASE + 0x0218)
+#define MJPEG_BBC_DATA_CNT_REG      (NIEUPORT_BASE + 0x021C)
+#define MJPEG_BBC_COMMAND_REG       (NIEUPORT_BASE + 0x0220)
+#define MJPEG_BBC_BUSY_REG          (NIEUPORT_BASE + 0x0224)
+#define MJPEG_BBC_CTRL_REG          (NIEUPORT_BASE + 0x0228)
+#define MJPEG_BBC_CUR_POS_REG       (NIEUPORT_BASE + 0x022C)
+#define MJPEG_BBC_BAS_ADDR_REG      (NIEUPORT_BASE + 0x0230)
+#define MJPEG_BBC_STRM_CTRL_REG     (NIEUPORT_BASE + 0x0234)
+#define MJPEG_BBC_FLUSH_CMD_REG     (NIEUPORT_BASE + 0x0238)
+
+#define JPU_MMU_TRI (NIEUPORT_BASE +0x400)
+
+#define TBU_NUM 32
+#define MJPEG_MMU_TTBLR_BASE         (MMU_BASE + 0x40)
+#define MJPEG_MMU_TTBHR_BASE         (MMU_BASE + 0x44)
+#define MJPEG_MMU_TCR0_BASE          (MMU_BASE + 0x48)
+#define MJPEG_MMU_TCR1_BASE          (MMU_BASE + 0x4c)
+#define MJPEG_MMU_TBU_STATUS_BASE    (MMU_BASE + 0x50)
+#define MJPEG_MMU_TBUx_STEP          0x20
+#define MJPEG_MMU_BVA_LO             (MMU_BASE + 0x00)
+#define MJPEG_MMU_BVA_HI             (MMU_BASE + 0x04)
+#define MJPEG_MMU_TIMEOUT_VA_ADDR_LO (MMU_BASE + 0x08)
+#define MJPEG_MMU_TIMEOUT_VA_ADDR_HI (MMU_BASE + 0x0C)
+#define MJPEG_MMU_IRQ_STATUS         (MMU_BASE + 0x10)
+#define MJPEG_MMU_IRQ_ENABLE         (MMU_BASE + 0x14)
+#define MJPEG_MMU_TIMEOUT_VALUE      (MMU_BASE + 0x18)
+#define MJPEG_MMU_ERROR_CLEAR        (MMU_BASE + 0x1C)
+#define MJPEG_MMU_LAST_VA_ADDR_LO    (MMU_BASE + 0x20)
+#define MJPEG_MMU_LAST_VA_ADDR_HI    (MMU_BASE + 0x24)
+#define MJPEG_MMU_LAST_PA_ADDR_LO    (MMU_BASE + 0x28)
+#define MJPEG_MMU_LAST_PA_ADDR_HI    (MMU_BASE + 0x2C)
+#define MJPEG_MMU_VERSION            (MMU_BASE + 0x3C)
+
+#define BASE_VIRTUAL_ADDRESS	0x80000000
+#define VA_STEP_PER_TBU		0x2000000
+#define MAX_ENTRIES_PER_TTB	8096
+#define ENTRY_SIZE		4
+#define MAX_SIZE_PER_TTB	(MAX_ENTRIES_PER_TTB*ENTRY_SIZE)
+#define DEFAULT_TIMEOUT_CYCS	0x80000
+#define SPACEMIT_MJPEG_MMU_PGSIZE_BITMAP 0x02FFF000	/* 4K~32M */
+
+#define TBU_INSTANCES_NUM	2
+
+#define TTB_ENTRY_SHIFT		12
+#define AQUIRE_TIMEOUT_MS	100
+#endif
-- 
2.47.0

